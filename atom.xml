<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>mpickering.github.io</title>
    <link href="http://mpickering.github.io/atom.xml" rel="self" />
    <link href="http://mpickering.github.io" />
    <id>http://mpickering.github.io/atom.xml</id>
    <author>
        <name>Matthew Pickering</name>
        <email>matthewtpickering@gmail.com</email>
    </author>
    <updated>2019-06-11T00:00:00Z</updated>
    <entry>
    <title>Tools for working on GHC</title>
    <link href="http://mpickering.github.io/posts/2019-06-11-ghc-tools.html" />
    <id>http://mpickering.github.io/posts/2019-06-11-ghc-tools.html</id>
    <published>2019-06-11T00:00:00Z</published>
    <updated>2019-06-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Tools for working on GHC </h2>
<p class="text-muted">
    Posted on June 11, 2019
    
</p>

<p>In the old days of the Make build system, the only reliable IDE-like feature which was useful whilst working on GHC was a tags file. Even loading GHC into GHCi was not easily possible, the most simple of interactive development workflows. Thankfully now times are changing, there are now build targets to start a GHCi session which enables developers to use tooling such as <a href="https://github.com/ndmitchell/ghcid">ghcid</a> or <a href="https://marketplace.visualstudio.com/items?itemName=dramforever.vscode-ghc-simple">vscode-ghc-simple</a>. Something which is quite important when working on a project with over 500 modules!</p>
<p>In this post we’ll briefly describe some recent advancements in developer tooling which have been made possible by the move to Hadrian.</p>
<!--more-->
<h2 id="ghci"><code>ghci</code></h2>
<p>The first target allows a developer to load GHC into GHCi. The <code>-fno-code</code> option is used which means that you can’t evaluate any expressions. It is useful for rapid feedback.</p>
<script id="asciicast-EKHiPuGgxhXz0ZHQgtR3OQd9G" src="https://asciinema.org/a/EKHiPuGgxhXz0ZHQgtR3OQd9G.js" async></script>
<h2 id="ghcid"><code>ghcid</code></h2>
<p><code>ghcid</code> can be used whilst working on <code>ghc</code> by invoking the <code>./hadrian/ghci.sh</code> target.</p>
<script id="asciicast-HAu0U5cVbneuujaoUA92Nxld5" src="https://asciinema.org/a/HAu0U5cVbneuujaoUA92Nxld5.js" async></script>
<p>There is a <code>.ghcid</code> file included <a href="https://gitlab.haskell.org/ghc/ghc/blob/master/.ghcid">in the repo</a> which includes some basic settings instructing <code>.ghcid</code> to reload the session if <code>hadrian/</code> changes. It might also be useful to add further directories here so that working with the many components of <code>ghc</code> is seamless.</p>
<h2 id="haskell-ide-engine"><code>haskell-ide-engine</code></h2>
<p>Once you have a working <code>ghci</code> target then in theory it becomes possible to use all other tooling with your build system. I realised that it would be possible to get <code>haskell-ide-engine</code> working with <code>ghc</code> but it required a <a href="https://github.com/haskell/haskell-ide-engine/pull/1126">very significant refactor</a>.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">
Here's a short demo of using haskell-ide-engine on GHC's code base using my fork which integrates HIE into hadrian/cabal/rules_haskell/stack/obelisk <a href="https://t.co/rA1ps7dSb1">pic.twitter.com/rA1ps7dSb1</a>
</p>
— Matthew Pickering (<span class="citation" data-cites="mpickering_">(<span class="citeproc-not-found" data-reference-id="mpickering_"><strong>???</strong></span>)</span>) <a href="https://twitter.com/mpickering_/status/1110874588509016064?ref_src=twsrc%5Etfw">March 27, 2019</a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>As a result, the branch can’t easily be merged back into the main repo but once it is merged then <code>haskell-ide-engine</code> will be more flexible and target agnostic.</p>
<h2 id="future-work-running-main">Future work: running <code>:main</code></h2>
<p>A final <a href="https://gitlab.haskell.org/ghc/ghc/issues/16672">goal</a> is to be able to run GHC’s <code>main</code> function from inside the interpreter. In order to do this it’s necessary to interpret the code rather than pass <code>-fno-code</code>. With some modifications to the <code>./hadrian/ghci.sh</code> script and patches by Michael Sloan we have been able to load load <code>ghc</code> into <code>GHCi</code> in the interpreted mode.</p>
<p>Unfortunately, this isn’t enough as in order to build programs with <code>HEAD</code> you also need to build libraries such as <code>base</code> with <code>HEAD</code>. The way around this is to first compile stage2 and then use the stage2 compiler to launch GHCi and load GHC into that. Then the libraries will be the correct versions and can be used to compile other modules.</p>
<p>A few months ago I got this working but since then it seems that the workflow <a href="https://gitlab.haskell.org/ghc/ghc/issues/16797">has been broken</a>. It’s a bit unfortunate that you have to jump through so many hoops in order to compile even a simple module but this is a unavoidable consequence of how GHC compiles and uses modules.</p>
<h3 id="ghci-debugger">GHCi Debugger</h3>
<p>Once you can execute <code>:main</code>, you can also use the GHCi debugger to debug GHC itself! This works without any problems but until you can use <code>:main</code> to compile programs then its of limited utility. I used the debugger to find the original reason why <code>:main</code> was failing whe compiling a program.</p>
]]></summary>
</entry>
<entry>
    <title>Making use of GHC bindists built by GitLab CI</title>
    <link href="http://mpickering.github.io/posts/2019-06-11-ghc-artefact.html" />
    <id>http://mpickering.github.io/posts/2019-06-11-ghc-artefact.html</id>
    <published>2019-06-11T00:00:00Z</published>
    <updated>2019-06-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Making use of GHC bindists built by GitLab CI </h2>
<p class="text-muted">
    Posted on June 11, 2019
    
</p>

<p>The new GHC GitLab CI infrastructure builds hundreds of different commits a week. Each commit on <code>master</code> is built, as well as any merge requests; each build produces an bindist which can be downloaded and installed on the relevant platform.</p>
<p><a href="https://github.com/mpickering/ghc-artefact-nix"><code>ghc-artefact-nix</code></a> provides a program <code>ghc-head-from</code> which downloads and enters a shell providing an artefact built with GitLab CI.</p>
<!--more-->
<h2 id="using-ghc-artefact-nix">Using <code>ghc-artefact-nix</code></h2>
<p>You can install <code>ghc-head-from</code> using <a href="https://github.com/nix-community/NUR"><code>NUR</code></a>.</p>
<pre><code>nix-shell -p nur.repos.mpickering.ghc-head-from</code></pre>
<p>There are three modes of operation.</p>
<h3 id="grab-a-recent-commit-from-master">Grab a recent commit from <code>master</code></h3>
<pre><code>ghc-head-from</code></pre>
<h3 id="grab-a-merge-request">Grab a merge request</h3>
<pre><code>ghc-head-from 1107</code></pre>
<h3 id="grab-a-specific-bindist-for-example-from-a-branch-or-fork">Grab a specific bindist (for example, from a branch or fork)</h3>
<pre><code>ghc-head-from https://gitlab.haskell.org/ghc/ghc/-/jobs/98842/artifacts/raw/ghc-x86_64-fedora27-linux.tar.xz</code></pre>
<p>The URL you provide has to be a direct link to a <code>fedora27</code> bindist.</p>
<h2 id="technical-details">Technical Details</h2>
<p>The bindist is downloaded from the (very flaky) CDN and patched to remove platform specific paths. The <code>fedora27</code> job is used because it is built using <code>ncurses6</code> which works better with nix.</p>
<h3 id="using-an-artefact-in-a-nix-expression">Using an artefact in a nix expression</h3>
<p>The <a href="https://github.com/mpickering/old-ghc-nix"><code>old-ghc-nix</code></a> repo provides a <code>mkGhc</code> function which can be used in a nix expression to create an attribute for a specific bindist. It is also packaged using <code>NUR</code>.</p>
<pre><code>nur.repos.mpickering.ghc.mkGhc
  {  url = &quot;https://gitlab-artifact-url.com&quot;; hash = &quot;sha256&quot;; ncursesVersion = &quot;6&quot;; }</code></pre>
<p>The <code>ncursesVersion</code> attribute is important to set for <code>fedora27</code> jobs as the function assumes that the bindist was built with <code>deb8</code> which uses <code>ncurses5</code>.</p>
<p>If you plan on using the artefact for a while then make sure you click the “keep” button on the artefact download page as otherwise it will be deleted after a week. This is very useful if you are developing a library against an unreleased version of the compiler and want to make sure all your collaborators are using the same version of GHC.</p>
]]></summary>
</entry>
<entry>
    <title>A three-stage program you definitely want to write</title>
    <link href="http://mpickering.github.io/posts/2019-02-14-stage-3.html" />
    <id>http://mpickering.github.io/posts/2019-02-14-stage-3.html</id>
    <published>2019-02-14T00:00:00Z</published>
    <updated>2019-02-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> A three-stage program you definitely want to write </h2>
<p class="text-muted">
    Posted on February 14, 2019
    
</p>

<p>Writing programs explicitly in stages gives you guarantees that abstraction will be removed. A guarantee that the optimiser most certainly does not give you.</p>
<p>After spending the majority of my early 20s inside the optimiser, I decided enough was enough and it was time to gain back control over how my programs were partially evaluated.</p>
<p>So in this post I’ll give an example of how I took back control and eliminated two levels of abstraction for an interpreter by writing a program which runs in three stages.</p>
<p>Enter: An applicative interpreter for Hutton’s razor.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">data</span> <span class="dt">Expr</span> <span class="fu">=</span> <span class="dt">Val</span> <span class="dt">Int</span> <span class="fu">|</span> <span class="dt">Add</span> <span class="dt">Expr</span> <span class="dt">Expr</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="ot">eval ::</span> <span class="dt">Applicative</span> m <span class="ot">=&gt;</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> m <span class="dt">Int</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4">eval (<span class="dt">Val</span> n) <span class="fu">=</span> pure n</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">eval (<span class="dt">Add</span> e1 e2) <span class="fu">=</span> (<span class="fu">+</span>) <span class="fu">&lt;$&gt;</span> eval e1 <span class="fu">&lt;*&gt;</span> eval e2</a></code></pre></div>
<p>Written simply at one level, there are two levels of abstraction which could be failed to be eliminated.</p>
<ol type="1">
<li>If we statically know the expression we can eliminate <code>Expr</code>.</li>
<li>If we statically know which <code>Applicative</code> then we can remove the indirection from the typeclass.</li>
</ol>
<p>Using typed Template Haskell we’ll work out how to remove both of these layers.</p>
<!--more-->
<h2 id="eliminating-the-expression">Eliminating the Expression</h2>
<p>First we’ll have a look at how to stage the program just to eliminate the expression without discussion the application fragment. This is a two-stage program.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">module</span> <span class="dt">Two</span> <span class="kw">where</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="kw">import</span> <span class="dt">Language.Haskell.TH</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="kw">data</span> <span class="dt">Expr</span> <span class="fu">=</span> <span class="dt">Val</span> <span class="dt">Int</span> <span class="fu">|</span> <span class="dt">Add</span> <span class="dt">Expr</span> <span class="dt">Expr</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="ot">eval ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">TExpQ</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8">eval (<span class="dt">Val</span> n) <span class="fu">=</span> [<span class="fu">||</span> n <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">eval (<span class="dt">Add</span> e1 e2) <span class="fu">=</span> [<span class="fu">||</span> <span class="fu">$$</span>(eval e1) <span class="fu">+</span> <span class="fu">$$</span>(eval e2) <span class="fu">||</span>]</a></code></pre></div>
<p>The eval function takes an expression and generates code which unrolls the expression that needs to be evaluated.</p>
<p>Splicing in <code>eval</code> gives us a chain of additions which are computed at run-time.</p>
<pre><code>$$(eval (Add (Val 1) (Val 2)))
=&gt; 1 + 2</code></pre>
<p>By explicitly seperating the program into stages we know that there will be no mention of <code>Expr</code> in the resulting program.</p>
<h2 id="eliminating-the-applicative-functor">Eliminating the Applicative Functor</h2>
<p>That’s good. Eliminating the <code>Expr</code> data type was easy. We’ll have to work a bit more to eliminate the applicative.</p>
<p>In the first stage, we will eliminate the expression in the same manner but instead of producing an <code>Int</code>, we will produce a <code>SynApplicative</code> which is a syntactic representation of an applicative. This allows us to inspect the structure of the program in the second stage and remove that overhead as well.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">data</span> <span class="dt">SynApplicative</span> a <span class="kw">where</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">  <span class="dt">Return</span><span class="ot"> ::</span> <span class="dt">WithCode</span> a <span class="ot">-&gt;</span> <span class="dt">SynApplicative</span> a</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">  <span class="dt">App</span><span class="ot">  ::</span> <span class="dt">SynApplicative</span> (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> <span class="dt">SynApplicative</span> a <span class="ot">-&gt;</span> <span class="dt">SynApplicative</span> b</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"></a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="kw">data</span> <span class="dt">WithCode</span> a <span class="fu">=</span> <span class="dt">WithCode</span> {<span class="ot"> _val ::</span> a,<span class="ot"> _code ::</span> <span class="dt">TExpQ</span> a }</a></code></pre></div>
<p><code>WithCode</code> is a wrapper which pairs a value with a code fragment which was used to produce that value.</p>
<p>If you notice in the earlier example, this wasn’t necessary when it was known that we needed to persist an <code>Int</code>, as there is a <code>Lift</code> instance for <code>Int</code>. However, in general, not all values can be persisted so using <code>WithCode</code> is more general and flexible, if a bit more verbose.</p>
<p><code>elimExpr</code> eliminates the first layer of abstraction and returns code which generates a <code>SynApplicative</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="ot">elimExpr ::</span> <span class="dt">Expr</span> <span class="ot">-&gt;</span> <span class="dt">TExpQ</span> (<span class="dt">SynApplicative</span> <span class="dt">Int</span>)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">elimExpr (<span class="dt">Val</span> n) <span class="fu">=</span> [<span class="fu">||</span> <span class="dt">Return</span> (<span class="dt">WithCode</span> n (liftT n)) <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">elimExpr (<span class="dt">Add</span> e1 e2) <span class="fu">=</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4">   [<span class="fu">||</span> <span class="dt">Return</span> (<span class="dt">WithCode</span> (<span class="fu">+</span>) codePlus)</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">        <span class="ot">`App`</span> <span class="fu">$$</span>(elimExpr e1)</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">        <span class="ot">`App`</span> <span class="fu">$$</span>(elimExpr e2) <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb5-7" data-line-number="7"></a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="ot">liftT ::</span> <span class="dt">Lift</span> a <span class="ot">=&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">TExpQ</span> a</a>
<a class="sourceLine" id="cb5-9" data-line-number="9">liftT <span class="fu">=</span> unsafeTExpCoerce <span class="fu">.</span> lift</a>
<a class="sourceLine" id="cb5-10" data-line-number="10"></a>
<a class="sourceLine" id="cb5-11" data-line-number="11">codePlus <span class="fu">=</span> [<span class="fu">||</span> (<span class="fu">+</span>) <span class="fu">||</span>]</a></code></pre></div>
<p>In the case for <code>Add</code> we encounter a situation where we would have liked to use nested brackets to persist the value of <code>[|| (+) ||]</code>. Instead you have to lift it to the top level and then perist that identifer.</p>
<p>Next, it’s time to provide an interpreter to remove the abstraction of the applicative. In order to do this, we need to provide a dictionary which will be used to give the interpretation of the applicative commands.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">data</span> <span class="dt">ApplicativeDict</span> m <span class="fu">=</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2">  <span class="dt">ApplicativeDict</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">    {<span class="ot"> _return ::</span> (forall a <span class="fu">.</span> <span class="dt">WithCode</span> (a <span class="ot">-&gt;</span> m a)),</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="ot">      _ap     ::</span> (forall a b <span class="fu">.</span> <span class="dt">WithCode</span> (m (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> m a <span class="ot">-&gt;</span> m b))</a>
<a class="sourceLine" id="cb6-5" data-line-number="5">    }</a></code></pre></div>
<p><code>WithCode</code> is necessary again as it will be used to generate a program so it’s necessary to know how to implement the methods.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb7-1" data-line-number="1">elimApplicative</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="ot">  ::</span> <span class="dt">SynApplicative</span> a</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">  <span class="ot">-&gt;</span> <span class="dt">ApplicativeDict</span> m</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">  <span class="ot">-&gt;</span> <span class="dt">TExpQ</span> (m a)</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">elimApplicative (<span class="dt">Return</span> v) d<span class="fu">@</span><span class="dt">ApplicativeDict</span>{<span class="fu">..</span>}</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">  <span class="fu">=</span> [<span class="fu">||</span> <span class="fu">$$</span>(_code _return) <span class="fu">$$</span>(_code v) <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">elimApplicative (<span class="dt">App</span> e1 e2) d<span class="fu">@</span><span class="dt">ApplicativeDict</span>{<span class="fu">..</span>}</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">  <span class="fu">=</span> [<span class="fu">||</span> <span class="fu">$$</span>(_code _ap) <span class="fu">$$</span>(elimApplicative e1 d) <span class="fu">$$</span>(elimApplicative e2 d) <span class="fu">||</span>]</a></code></pre></div>
<p>This interpretation is very boring as it just amounts to replacing all the constructors with their implementations. However, it is exciting that we have guaranteed the removal of the overhead of the applicative abstraction.</p>
<h2 id="running-the-splice">Running the Splice</h2>
<p>Now we written two functions independently to to eliminate the two layers, they need to be combined together. This is the birth of our three-stage program.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">import</span> <span class="dt">Three</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="ot">elim ::</span> <span class="dt">Identity</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">elim <span class="fu">=</span> <span class="fu">$$</span>(elimApplicative <span class="fu">$$</span>(elimExpr (<span class="dt">Add</span> (<span class="dt">Val</span> <span class="dv">1</span>) (<span class="dt">Val</span> <span class="dv">2</span>))) identityDict)</a>
<a class="sourceLine" id="cb8-5" data-line-number="5"></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">identityDict <span class="fu">=</span> <span class="dt">ApplicativeDict</span>{<span class="fu">..</span>}</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">  <span class="kw">where</span></a>
<a class="sourceLine" id="cb8-8" data-line-number="8">    _return <span class="fu">=</span> <span class="dt">WithCode</span> <span class="dt">Identity</span> [<span class="fu">||</span> <span class="dt">Identity</span> <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">    _ap <span class="fu">=</span> <span class="dt">WithCode</span> idAp [<span class="fu">||</span> idAp <span class="fu">||</span>]</a>
<a class="sourceLine" id="cb8-10" data-line-number="10"></a>
<a class="sourceLine" id="cb8-11" data-line-number="11"><span class="ot">idAp ::</span> <span class="dt">Identity</span> (a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> <span class="dt">Identity</span> a <span class="ot">-&gt;</span> <span class="dt">Identity</span> b</a>
<a class="sourceLine" id="cb8-12" data-line-number="12">idAp (<span class="dt">Identity</span> f) (<span class="dt">Identity</span> a) <span class="fu">=</span> <span class="dt">Identity</span> (f a)</a></code></pre></div>
<p><code>elim</code> is the combination of <code>elimApplicative</code> and <code>elimExpr</code>. The nested splices indicate that the program is more than two levels.</p>
<p>Using <code>-ddump-splices</code> we can have a look at the program that gets generated.</p>
<pre><code>Test.hs:10:30-59: Splicing expression
    elimExpr (Add (Val 1) (Val 2))
  ======&gt;
    ((Return ((WithCode (+)) codePlus)
        `App` Return ((WithCode 1) (liftT 1)))
       `App` Return ((WithCode 2) (liftT 2)))
Test.hs:10:11-73: Splicing expression
    elimApplicative $$(elimExpr (Add (Val 1) (Val 2))) identityDict
  ======&gt;
    (idAp ((idAp (Identity (+))) (Identity 1))) (Identity 2)</code></pre>
<p>Both steps appear in the debug output with the code which was produced at each step. Notice that we had very precise control over what code was generated and that functions like <code>idAp</code> are not inlined. In this case, the compiler will certainly inline <code>idAp</code> and so on but in general it might be useful to generate code which contains calls to <code>GHC.Exts.inline</code> to force even recursive functions to be inlined once.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In general, splitting your program up into stages is quite difficult so mechanisms like type class specialisation will be easier to achieve. In controlled situations though, staging gives you the guarantees you need.</p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="https://www.reddit.com/r/haskell/comments/aqkv9k/a_threestage_program_you_definitely_want_to_write/">Reddit Discussion</a></li>
<li><a href="https://github.com/mpickering/three-level">Code</a></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Implementing Nested Quotations</title>
    <link href="http://mpickering.github.io/posts/2019-01-31-nested-brackets.html" />
    <id>http://mpickering.github.io/posts/2019-01-31-nested-brackets.html</id>
    <published>2019-01-31T00:00:00Z</published>
    <updated>2019-01-31T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Implementing Nested Quotations </h2>
<p class="text-muted">
    Posted on January 31, 2019
    
</p>

<p>Quotation is one of the key elements of metaprogramming. Quoting an expression <code>e</code> gives us a representation of <code>e</code>.</p>
<pre><code>[| e |] :: Repr</code></pre>
<p>What this representation is depends on the metaprogramming framework and what we can do with the representation depends on the representation. The most common choice is to dissallow any inspection of the representation type relying on the other primative operation, the splice, in order to insert quoted values into larger programs.</p>
<p>The purpose of this post is to explain how to implemented nested quotations. From our previous example, quoting a term <code>e</code>, gives us a term which represents <code>e</code>. It follows that we should be allowed to nest quotations so that quoting a quotation gives us a representation of that quotation.</p>
<pre><code>[| [| 4 + 5 |] |]</code></pre>
<p>However, nesting brackets in this manner has been disallowed in Template Haskell for a number of years despite nested splices being permitted. I wondered why this restriction was in place and it seemed that <a href="https://mail.haskell.org/pipermail/ghc-devs/2019-January/016939.html">no one knew the answer</a>. It turns out, there was no technical reason and implementing nested brackets is straightforward once you think about it correctly.</p>
<!--more-->
<h2 id="template-haskell">Template Haskell</h2>
<p>We will now be concrete and talk about how these mechanisms are implemented in Template Haskell.</p>
<p>In Template Haskell the representation type of expressions is called <code>Exp</code>. It is a <a href="http://hackage.haskell.org/package/template-haskell-2.14.0.0/docs/Language-Haskell-TH-Syntax.html#t:Exp">simple ADT</a> which mirrors source Haskell programs very closely. For example quoting <code>2 + 3</code> might be represented by:</p>
<pre><code>[| 2 + 3 |] :: Exp
= InfixE (Just (LitE 5)) (VarE +) (Just (LitE 5))</code></pre>
<p>Because <code>Exp</code> is a normal data type we can define its representation in the same manner as any user defined data type. This is the purpose of the <code>Lift</code> type class which defines how to turn a value into its representation.</p>
<pre><code>class Lift t where
  lift :: t -&gt; Q Exp</code></pre>
<p>So we just need to implement <code>instance Lift (Q Exp)</code> and we’re done. To do that we implement a general instance for <code>Lift (Q a)</code> and then also an instance for <code>Exp</code>.</p>
<pre><code>instance Lift a =&gt; Lift (Q a) where
  lift qe = qe &gt;&gt;= \b&#39; -&gt; lift b&#39; &gt;&gt;= \b&#39;&#39; -&gt; return ((VarE &#39;return) `AppE` b&#39;&#39;)</code></pre>
<p>This instance collapses effects from building the inner code value into a single outer layer. In order to make the types line up correctly, we have to insert a call to <code>return</code> to the result of lifting the inner expression.</p>
<p>Instances for <code>Exp</code> and all its connected types are straightforward to define and thankfully we can use the <code>DeriveLift</code> extension in order to derive them.</p>
<pre><code>deriving instance Lift Exp
... 40 more instances
deriving instance Lift PatSynDir</code></pre>
<p>It’s now possible to write a useless program which lifts a boolean value twice before splicing it twice to get back the original program.</p>
<pre><code>-- foo = True
foo :: Bool
foo = $($(lift (lift True)))</code></pre>
<p>Running this program with <code>-ddump-splices</code> would show us that when the first splice is run, the code that is insert is the representation of <code>True</code>. After the second splice is run, this representation is turned back into <code>True</code>.</p>
<h2 id="cross-stage-persistance">Cross Stage Persistance</h2>
<p>If you use variables in a bracket the compiler has to persist their value from one stage to another so that they remain bound and bound to the correct value when we splice in the quote.</p>
<p>For example, quoting <code>x</code>, we need to remember that the <code>x</code> refers to the <code>x</code> bound to the top-level which is equal to <code>5</code>.</p>
<pre><code>x = 5

foo = [| x |]</code></pre>
<p>If we didn’t when splicing in <code>foo</code>, in another module, we would use whatever <code>x</code> was in scope or end up with an unbound reference to <code>x</code>. No good at all.</p>
<p>For a locally bound variable, we can’t already precisely know the value of the variable. We will only know it later at runtime when the function is applied.</p>
<pre><code>foo x = [| x |]</code></pre>
<p>Thus, we must know for any value that <code>x</code> can take, how we construct its representation. If we remember, that’s precisely what the <code>Lift</code> class is for. So, to correct this cross-stage reference, we replace the variable <code>x</code> with a splice (which lowers the level by one) and a call to <code>lift</code>.</p>
<pre><code>foo x = [| $(lift x) |]</code></pre>
<h3 id="nesting-brackets">Nesting Brackets</h3>
<p>The logic for persisting variables has to be extended to work with nested brackets.</p>
<pre><code>foo3 :: Lift a =&gt; a -&gt; Q Exp
foo3 x = [| [| x |] |]</code></pre>
<p>In <code>foo3</code>, <code>x</code> is used at level 2 but defined at level 0, hence we must insert two levels of splices and two levels of lifting to rectify the stages.</p>
<pre><code>foo3 :: Lift a =&gt; a -&gt; Q Exp
foo3 x = [| [| $($(lift(lift x))) |] |]</code></pre>
<p>Now with nested brackets, you can also lift variables defined in future stages.</p>
<pre><code>foo4 :: Q Exp
foo4 = [| \x -&gt; [| x |] |]</code></pre>
<p>Now <code>x</code> is defined at stage 1 and used in stage 2. So, like normal, we need to insert a lift and splice in order to realign the stages. This time, just one splice as we just need to lift it one level.</p>
<pre><code>foo4 :: Q Exp
foo4 = [| \x -&gt; [| $(lift x) |] |]</code></pre>
<h1 id="implementing-nested-brackets">Implementing Nested Brackets</h1>
<h2 id="implementing-splices">Implementing Splices</h2>
<p>After renaming a bracket, all the splices inside the bracket are moved into an associated environment.</p>
<pre><code>foo = [| $(e) |]
=&gt; [| x |]_{ x = e }</code></pre>
<p>When renaming the RHS of <code>foo</code>, we replace the splice of <code>e</code> with a new variable <code>x</code>, this is termed the “splice point” for the expression <code>e</code>. Then, a new binding is added to the environment for the bracket which says that any reference to <code>x</code> inside the bracket refers to <code>e</code>. That means when we make the representation of the code inside the bracket, occurences of <code>x</code> are replaced with <code>e</code> directly (rather than a representation of <code>x</code>) in the program.</p>
<p>The same mechanism is used for the implicit splices we create by instances of cross-stage persistence.</p>
<pre><code>qux x = [| x |]
        =&gt; [| $(lift x) |]
        =&gt; [| x&#39; |]_{ x&#39; = lift x }</code></pre>
<p>The environment is special in the sense that it connects a stage 1 variable with an expression at stage 0.</p>
<p>How is this implemented? When we see a splice we rename it and the write it to a state variable whose scope is delimited by the bracket. Once the contents of the bracket is finished being renamed we read the contents and use that as the environment.</p>
<h2 id="generalisation-to-n-levels">Generalisation to n-levels</h2>
<p>If we insert an implicit splice for a variable with a two stage difference, we need to propagate the splice outwards two levels to correct the stage difference.</p>
<pre><code>foo n = [| [| n |] |]
      =&gt; [| [| $($(lift n)) |] |]
      =&gt; [| [| x |]_{x = y} |]_{y = lift (lift n) }</code></pre>
<p>As such, we annotate each pending splice with its target level and float it outwards as far as it needs to go. As the splice moves outwards, we leave behind trivial bindings which connect together the different stages.</p>
<h2 id="representing-quotes">Representing Quotes</h2>
<p>Template Haskell represents renamed terms so that references remain constent after splicing. As such, our representation of a quotation in the TH AST should reflect the renamed form of brackets which includes the environment.</p>
<pre><code>data Exp = ... | BrackE [(Var, Exp)] Exp | ...</code></pre>
<p>The constructor therefore takes a list which is the environment mapping splice points to expressions and a representation of the quoted expression.</p>
<p>It is invariant that there are no splice forms in renamed syntax as they are all replaced during renaming into this environment form.</p>
<p>To represent a simple quoted expression will have an empty environment but if we also use splices then these are included as well.</p>
<pre><code>[| [| 4 |] |] =&gt; BrackE [] (representation of 4)

[| [| $(foo) |] |] =&gt; BrackE [(x, representation of foo)] (representation of x)</code></pre>
<h1 id="conclusion">Conclusion</h1>
<p>Those are the details of implementing nested brackets, if you ever need to for your own language. In the end, the patch was quite simple but it took quite a bit of thinking to work out the correct way to propagate the splices and build the correct representation.</p>
]]></summary>
</entry>
<entry>
    <title>Packaging a Haskell library for artefact evaluation using nix</title>
    <link href="http://mpickering.github.io/posts/2018-09-19-nix-artefacts.html" />
    <id>http://mpickering.github.io/posts/2018-09-19-nix-artefacts.html</id>
    <published>2018-09-19T00:00:00Z</published>
    <updated>2018-09-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Packaging a Haskell library for artefact evaluation using nix </h2>
<p class="text-muted">
    Posted on September 19, 2018
    
</p>

<p>This year I packaged two artefacts for the ICFP artefact evaluation process. This post explains the system I used to make it easy to produce the docker images using nix. I hope this documentation will be useful for anyone else submitting a Haskell library for evaluation.</p>
<p>The end result will be an <code>artefact.nix</code> file which is used to build a docker image to submit. It will be an entirely reproducible process as we will fix the versions of all the dependencies we use.</p>
<!--more-->
<h2 id="the-structure-of-the-artefact">The structure of the artefact</h2>
<p>In this example, I am going to package the artefact from the paper <a href="https://dl.acm.org/citation.cfm?id=3236780">“Generic Deriving of Generic Traversals”</a>. The artefact was a Haskell library and an executable which ran some benchmarks. The resulting artefact will be a docker image which contains:</p>
<ol type="1">
<li>The source code of the library</li>
<li>The source code for the benchmarks</li>
<li>The executable of the benchmarks</li>
<li>An environment where it is possible to compile the library and benchmarks</li>
</ol>
<p>To start with, I will assume that we have placed the source code and benchmarks code in our current directory. We will add the rest of the files</p>
<pre><code>&gt;&gt;&gt; ls
generic-lens-1.0.0.1/
benchmarks/</code></pre>
<h2 id="step-1-pinning-nixpkgs">Step 1: Pinning nixpkgs</h2>
<p>The most important step of the whole process is to “pin” our version of nixpkgs to a specific version so that anyone else trying to build the image will use the same versions of all the libraries and system dependencies.</p>
<p>Once we have established a commit of nixpkgs that out package builds with. We can use <code>nix-prefetch-git</code> in order to create <code>nixpkgs.json</code> which will provide the information about the pin.</p>
<pre><code>nix-prefetch-git --rev 651239d5ee66d6fe8e5e8c7b7a0eb54d2f4d8621 --url https://github.com/NixOS/nixpkgs.git &gt; nixpkgs.json</code></pre>
<p>Now we have a file, <code>nixpkgs.json</code> which specifies which version of nixpkgs we should use.</p>
<p>We then need to load this file. Some boilerplate, <code>nixpkgs.nix</code>, will do that for us.</p>
<pre><code>opts:
let
   hostPkgs = import &lt;nixpkgs&gt; {};
   pinnedVersion = hostPkgs.lib.importJSON ./nixpkgs.json;
   pinnedPkgs = hostPkgs.fetchFromGitHub {
     owner = &quot;NixOS&quot;;
     repo = &quot;nixpkgs&quot;;
     inherit (pinnedVersion) rev sha256;
   };
in import pinnedPkgs opts</code></pre>
<p><code>nixpkgs.nix</code> will be imported in <code>artefact.nix</code> and will determine precisely the version of all dependencies we will use.</p>
<h2 id="step-2-using-dockertools">Step 2: Using <code>dockerTools</code></h2>
<p>Now we have specified the set of dependencies we want to use we can go about starting to build our docker image. Nixpkgs provides a convenient set of functions called <code>dockerTools</code> in order to create docker images in a declarative manner. This is the start of our <code>artefact.nix</code> file.</p>
<pre><code>let
  pkgs = import ./nixpkgs.nix { };
in
with pkgs;
let
    debian = dockerTools.pullImage
      { imageName = &quot;debian&quot;
      ; imageTag = &quot;9.5&quot;
      ; sha256 = &quot;1jxci0ph7l5fh0mm66g4apq1dpcm5r7gqfpnm9hqyj7rgnh44crb&quot;; };
in
dockerTools.buildImage {
  name = &quot;generic-lens-artefact&quot;;

  fromImage = debian;

  contents = [  bashInteractive
                glibcLocales
             ];

  config = {
    Env = [&quot;LANG=en_US.UTF-8&quot;
           &quot;LOCALE_ARCHIVE=${glibcLocales}/lib/locale/locale-archive&quot;];
    WorkingDir = &quot;/programs&quot;;
  };
}</code></pre>
<p>This is the barebones example we’ll start from. We firstly import <code>nixpkgs.nix</code> which defines the package set we want to use. Our docker file will be based on <code>debian</code>, and so we use the <code>dockerTools.pullImage</code> function to get this base image. The <code>imageName</code> comes from docker hub and the <code>imageTag</code> indicates the specific tag.</p>
<p>This image is our base image when calling <code>dockerTools.buildImage</code>. For now, we add the basic packages <code>bashInteractive</code> and <code>glibcLocales</code>, in the next step we will add the specific contents that we need for our artefact.</p>
<p>Setting the <code>LANG</code> and <code>LOCALE_ARCHIVE</code> env vars is important for Haskell programs as otherwise you can run into strange encoding errors.</p>
<p>This is a complete image which can already be build with <code>nix-build artefact.nix</code>. The result will be a <code>.tar.gz</code> which can be loaded into docker and run as normal.</p>
<h2 id="step-3-including-the-artefact">Step 3: Including the artefact</h2>
<p>First we’ll deal with making the executable itself available on the image. Remember that the source code the the benchmarks, which is a normal Haskell package, is located in <code>benchmarks/</code>.</p>
<p>We need to tell nix how to build the benchmarks. The standard way to do this is to use <code>cabal2nix</code> to generate a package specification which we will pass to <code>haskellPackages.callPackage</code>.</p>
<pre><code>cabal2nix benchmarks/ &gt; benchmarks.nix</code></pre>
<p>This will produce a file which looks a bit like</p>
<pre><code>{ mkDerivation, base, criterion, deepseq, dlist, dump-core
, generic-lens, geniplate-mirror, haskell-src, lens, mtl, one-liner
, parallel, plugin, random, stdenv, syb, transformers, uniplate
, weigh
}:
mkDerivation {
  pname = &quot;benchmarks&quot;;
  version = &quot;0.1.0.0&quot;;
  src = ./benchmarks;
  isLibrary = false;
  isExecutable = true;
  executableHaskellDepends = [
    base criterion deepseq dlist dump-core generic-lens
    geniplate-mirror haskell-src lens mtl one-liner parallel plugin
    random syb transformers uniplate weigh
  ];
  license = stdenv.lib.licenses.bsd3;
}</code></pre>
<p>Now we will add the executable to the docker image. A new definition is created in the let bindings and then we add the executable to the <code>contents</code> of the image.</p>
<pre><code>run-benchmarks = haskellPackages.callPackage ./benchmarks.nix {};</code></pre>
<p>So now our <code>contents</code> section will look like:</p>
<pre><code>  contents = [  bashInteractive
                glibcLocales
                run-benchmarks
                ];</code></pre>
<p>When we build this image, the executable will be available on the path by default. In our case, the user will type <code>bench</code> and it will run the benchmarks.</p>
<h2 id="step-4-including-the-source-files">Step 4: Including the source files</h2>
<p>The next step is to add the source files to the image. To do this we use a the <code>runCommand</code> script to make a simple derivation which copies some files into the right place.</p>
<pre><code>benchmarks-raw = ./benchmarks;
benchmarks =
  runCommand &quot;benchmarks&quot; {} &#39;&#39;
  mkdir -p $out/programs
  mkdir -p $out/programs/benchmarks
  cp -r ${benchmarks-raw}/* $out/programs/benchmarks
&#39;&#39;;</code></pre>
<p>All the derivation does is copy the directory into the nix store at a specific path. We then just add this to the <code>contents</code> list again and also do the same for the library itself and the README.</p>
<pre><code>  contents = [  bashInteractive
                glibcLocales
                run-benchmarks
                benchmarks
                readme
                library];</code></pre>
<p>Now once we build the docker image, we’ll have the executable <code>bench</code> available and also a file called <code>README</code> and two folders containing the library code and benchmarks code.</p>
<h2 id="step-5-an-environment-to-build-the-source-code">Step 5: An environment to build the source code</h2>
<p>Finally, we need to do two more things to make it possible to build the source programs in the container.</p>
<p>Including <code>cabal-install</code> in the contents is the first so that we can use <code>cabal</code> in the container.</p>
<pre><code>  contents = [  bashInteractive
                glibcLocales
                run-benchmarks
                benchmarks
                readme
                library
                cabal-install ];</code></pre>
<p>The second is much less obvious, we need to make sure that the necessary dependencies are already installed in the environment so that someone can just use <code>cabal build</code> in order to build the package. The way to achieve this is to modify the <code>benchmarks.nix</code> file and change <code>isLibrary</code> to <code>true</code>.</p>
<pre><code>-  isLibrary = false;
+  isLibrary = true;</code></pre>
<p>This means that all the build inputs for the benchmarks are propagated to the container so all the dependencies for the benchmarks will be available to rebuild them again.</p>
<h2 id="complete-artefact.nix">Complete <code>artefact.nix</code></h2>
<p>Here’s the complete <code>artefact.nix</code> that we ended up with. We also generated <code>nixpkgs.json</code>, <code>nixpkgs.nix</code> and <code>benchmarks.nix</code> along the way.</p>
<pre><code>let
  pkgs = import ./nixpkgs.nix {};
in
with pkgs;
let
    debian = dockerTools.pullImage
      { imageName = &quot;debian&quot;
      ; imageTag = &quot;9.5&quot;
      ; sha256 = &quot;1y4k42ljf6nqxfq7glq3ibfaqsq8va6w9nrhghgfj50w36bq1fg5&quot;; };

    benchmarks-raw = ./benchmarks;
    benchmarks =
      runCommand &quot;benchmarks&quot; {} &#39;&#39;
        mkdir -p $out/programs
        mkdir -p $out/programs/benchmarks
        cp -r ${benchmarks-raw}/* $out/programs/benchmarks
      &#39;&#39;;

    library-raw = ./generic-lens-1.0.0.1;
    library =
      runCommand &quot;benchmarks&quot; {} &#39;&#39;
        mkdir -p $out/programs
        mkdir -p $out/programs/library
        cp -r ${library-raw}/* $out/programs/library
      &#39;&#39;;

    readme-raw = ./README;
    readme =
      runCommand &quot;readme&quot; {} &#39;&#39;
        mkdir -p $out/programs
        cp ${readme-raw} $out/programs/README
      &#39;&#39;;

    run-benchmarks = haskellPackages.callPackage ./benchmarks.nix {};

in
dockerTools.buildImage {
  name = &quot;generic-lens-artefact&quot;;


  fromImage = debian;

  contents = [  bashInteractive
                cabal-install
                glibcLocales
                run-benchmarks
                benchmarks
                readme
                library];

  config = {
    Env = [&quot;LANG=en_US.UTF-8&quot;
           &quot;LOCALE_ARCHIVE=${glibcLocales}/lib/locale/locale-archive&quot;];
    WorkingDir = &quot;/programs&quot;;
  };
}</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>Hopefully this tutorial will be useful for anyone having to package a Haskell library in future. Each artefact is different so you’ll probably have to modify some of the steps in order to make it work perfectly for you. It’s also possible that the <code>dockerTools</code> interface will change but it should be possible to modify the examples here to adapt to any minor changes. If you’re already using nix, you probably know what you’re doing anyway.</p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="https://vaibhavsagar.com/blog/2018/05/27/quick-easy-nixpkgs-pinning/">Quick and Easy Nixpkgs Pinning - Vaibhav Sagar</a></li>
<li><a href="https://nixos.org/nixpkgs/manual/#sec-pkgs-dockerTools"><code>dockerTools</code> documentation</a></li>
<li><a href="https://www.software.ac.uk/blog/2017-10-05-reproducible-environments-nix">Reproducible Environments With Nix - Blair Archibald</a></li>
<li>Reddit comments</li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Using funflow to cache a nix based workflow</title>
    <link href="http://mpickering.github.io/posts/2018-09-12-funflow-nix.html" />
    <id>http://mpickering.github.io/posts/2018-09-12-funflow-nix.html</id>
    <published>2018-09-12T00:00:00Z</published>
    <updated>2018-09-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Using funflow to cache a nix based workflow </h2>
<p class="text-muted">
    Posted on September 12, 2018
    
</p>

<p>My latest project has been to plot a <a href="http://mpickering.github.io/maps.html">map of orienteering maps</a> in the UK. This post explains the technical aspects behind the project and primarily the use of <a href="https://hackage.haskell.org/package/funflow"><code>funflow</code></a> to turn my assortment of scripts into into a resumable workflow.</p>
<p>There was nothing wrong with my ad-hoc python and bash scripts but they downloaded and regenerated the whole output every time. The whole generation takes about 2 hours so it’s desirable to only recompute the necessary portions. This is where <code>funflow</code> comes in, by stringing together these scripts in their DSL, you get caching for free. The workflow is also highly parallelisable so in the future I could distribute the work across multiple machines if necessary.</p>
<p>The code for the project can be found <a href="https://github.com/mpickering/rg-map">here</a>.</p>
<p><img src="https://i.imgur.com/NVLui01.png" style="width: 50%; margin: auto; display: block" /></p>
<!--more-->
<h2 id="funflow"><code>funflow</code></h2>
<p>There are already two blog posts introducing the concepts of <code>funflow</code>.</p>
<ol type="1">
<li><a href="https://www.tweag.io/posts/2018-04-25-funflow.html">Funflow: Typed Resumable Workflows</a></li>
<li><a href="https://www.tweag.io/posts/2018-07-10-funflow-make.html">Funflow Example: Emulating Make</a></li>
</ol>
<p>The main idea is that you specify your workflow (usually a sequence of external scripts) using a DSL and then <code>funflow</code> will automatically cache and schedule the steps.</p>
<p>My primary motivation for using <code>funflow</code> was the automatic caching. The store is content addressed which means that the location for each file in the store depends on its contents. <code>funflow</code> performs two different types of caching.</p>
<ol type="1">
<li>Input-based caching: A flow will only be executed once for each set of inputs.</li>
<li>Output-based caching: If multiple different steps produce the same output then it will only be stored once in the store. Further steps will not be recomputed.</li>
</ol>
<p>The lack of output-based caching is one of the big missing features of nix which makes it unsuitable for this task. A content-addressed store where the address depends on the contents of the file is sometimes known as an <strong>intensional</strong> store. Nix’s store model is <strong>extensional</strong> as the store hash only depends on the inputs to the build.</p>
<p>An intensional store relies on the program producing deterministic output hashes. It can be quite difficult to track down why a step is not being cached when you are relying on the output’s being identified in the store.</p>
<h2 id="high-level-architecture">High-level architecture</h2>
<p>There are two outputs to the project.</p>
<ol type="1">
<li>A folder of map tiles rendered at different resolutions.</li>
<li>A HTML page which contains the javascript to display the map and markers.</li>
</ol>
<p>This folder is then uploaded to online storage and served as a static site.</p>
<p>The processing pipeline is as follows:</p>
<ol type="1">
<li>Find all the maps with location information from <a href="http://www.routegadget.co.uk/">routegadget.co.uk</a>.</li>
<li>Download the metainformation and map image for each map.</li>
<li>Convert the maps to a common image format.</li>
<li>Reproject the maps to remove any rotation.</li>
<li>Merge overlapping maps into groups.</li>
<li>Generate tiles at all the different resolutions.</li>
<li>Combine all the tiles groups together.</li>
<li>Generate the website with the map and location markers.</li>
</ol>
<p>As can be seen, the workflow is firstly highly parallelisable as much of the processing pipeline happens independently of other steps. However, the main goal is to avoid computing the tiles as much as possible as this is the step which takes by far the longest. At the time of writing there are about 500 maps to process. In general, there are about 5-10 maps added each week. Only recomputing the changed portions of the map saves a lot of time.</p>
<h2 id="implementation-using-funflow">Implementation using <code>funflow</code></h2>
<p>In theory, this is a perfect application for <code>funflow</code> but in order to achieve the perfect caching behaviour I had to rearchitecture several parts of the application.</p>
<h3 id="using-nix-scripts">Using nix scripts</h3>
<p>The recommended way to use <code>funflow</code> is to run each step of the flow in a docker container. I didn’t want to do this was my scripts already declared the correct environment to run in by using the <a href="http://iam.travishartwell.net/2015/06/17/nix-shell-shebang/"><code>nix-shell</code> shebang</a>.</p>
<pre><code>#! /usr/bin/env nix-shell
#! nix-shell -i bash -p gdal</code></pre>
<p>By placing these two lines at the top of the file, the script will be run using the <code>bash</code> interpreter with the <code>gdal</code> package available. This is more lightweight and flexible than using a docker image as I don’t have to regenerate a new docker image any time I make a change.</p>
<p>However, there is no native support for running these kinds of scripts built into <code>funflow</code>. It was easy enough to define my own function in order to run these kinds of scripts using the <code>external'</code> primitive.</p>
<p><code>nixScript</code> takes a boolean parameter indicating whether the script is pure and should be cached. The name of the script to run, the names of any files the script depends on and finally a function which supplies any additional arguments to the script.</p>
<pre><code>nixScriptX :: ArrowFlow eff ex arr =&gt; Bool
                                   -&gt; Path Rel File
                                   -&gt; [Path Rel File]
                                   -&gt; (a -&gt; [Param])
                                   -&gt; arr (Content Dir, a) CS.Item
nixScriptX impure script scripts params = proc (scriptDir, a) -&gt; do
  env &lt;- mergeFiles -&lt; absScripts scriptDir
  external&#39; props (\(s, args) -&gt; ExternalTask
        { _etCommand = &quot;perl&quot;
        , _etParams = contentParam (s ^&lt;/&gt; script) : params args
        , _etWriteToStdOut = NoOutputCapture
        , _etEnv = [(&quot;NIX_PATH&quot;, envParam &quot;NIX_PATH&quot;)] }) -&lt; (env, a)
  where
    props = def { ep_impure = impure }
    absScripts sd = map (sd ^&lt;/&gt;) (script : scripts)</code></pre>
<p>The use of <code>perl</code> as the command relies on <a href="http://perldoc.perl.org/perlrun.html">the behaviour</a> of <code>perl</code> that it will execute the <code>#!</code> line if it does not contain the word “perl”. Yes, this <a href="https://askubuntu.com/questions/850384/is-there-a-command-for-running-a-script-according-to-its-shebang-line/850387">is dirty</a>.</p>
<p>It would be desirable to set <code>NIX_PATH</code> to a fixed <code>nixpkgs</code> checkout by passing a tarball directly but this worked for now.</p>
<p>All the steps are then defined in terms of <code>nixScriptX</code> indirectly as two helper functions are defined for the two cases of a pure or impure scripts.</p>
<pre><code>nixScript = nixScriptX False
impureNixScript = nixScriptX True</code></pre>
<h2 id="step-1---finding-the-map-information">Step 1 - Finding the map information</h2>
<p>Now to the nitty gritty details.</p>
<p>Firstly, I had to decouple the processing of finding the map metainformation from downloading the image. Otherwise, I would end up doing a lot of redundant work downloading images multiple times.</p>
<p>The python script <code>scraper.py</code> executes a selenium driver to extract the map information. For each map, the metainformation is serialised to its own file in the output directory.</p>
<pre><code>scrape = impureNixScript [relfile|scraper.py|] [[relfile|shell.nix|]]
          (\() -&gt; [ outParam ])</code></pre>
<p>This step is marked as impure as we have to run it every time the flow runs to work out if we need to perform any more work.</p>
<p>It is important that the filename of the serialised information is the same if the content of the file is the same. Otherwise, <code>funflow</code> will calculate a different hash for the file. As such, we compute our own hash of the metainformation for the name the serialised file.</p>
<p>In the end the output directory looks like:</p>
<pre><code>9442c7eaa81f82f7e9889f6ee8382e8d047df76db2d5f6a6983d1c82399a2698.pickle
5e7e6994db565126a942d66a9435454d8b55cd7d3023dd37f64eca7bbb46df1f.pickle
...</code></pre>
<h3 id="gotcha-1-using-listdircontents-defeats-caching">Gotcha 1: Using <code>listDirContents</code> defeats caching</h3>
<p>Now that we have a directory containing all the metainformation, we want to split it up and then execute the fetching, converting and warping in parallel for all the images. My first attempt was</p>
<pre><code>meta_dir &lt;- step All &lt;&lt;&lt; scrape -&lt; (script_dir, ())
keys &lt;- listDirContents -&lt; meta_dir</code></pre>
<p>but this did not work and even if the keys remained the same, the images would be refetched. The problem was <a href="https://hackage.haskell.org/package/funflow-1.3.2/docs/Control-Funflow-Steps.html#v:listDirContents"><code>listDirContents</code></a> does not have the correct caching behaviour.</p>
<p><code>listDirContents</code> takes a <code>Content Dir</code> and returns a <code>[Content File]</code> as required but the <code>[Content File]</code> are pointers into places into the <code>Content Dir</code>. This means that if the location of <code>Content Dir</code> changes (if there are any changes or new additions to any files in the directory) then the location of <em>all</em> the <code>[Content File]</code> will also be changed. This means the next stage of recompilation will be triggered despite being unnecessary.</p>
<p>Instead, we have to put each file in the directory into its own store location so that the its location depends only on itself rather than the other contents of the directory. I defined the <code>splitDir</code> combinator in order to do this.</p>
<pre><code>splitDir :: ArrowFlow eff ex arr =&gt; arr (Content Dir) ([Content File])
splitDir = proc dir -&gt; do
  (_, fs) &lt;- listDirContents -&lt; dir
  mapA reifyFile -&lt; fs


-- Put a file, which might be a pointer into a dir, into its own store
-- location.
reifyFile :: ArrowFlow eff ex arr =&gt; arr (Content File) (Content File)
reifyFile = proc f -&gt; do
  file &lt;- getFromStore return -&lt; f
  putInStoreAt (\d fn -&gt; copyFile fn d) -&lt; (file, CS.contentFilename f)</code></pre>
<p>It could be improved by using a hardlink rather than <code>copyFile</code>.</p>
<h2 id="step-2-download-convert-and-warp">Step 2: Download, convert and warp</h2>
<p>Now we have split the metainformation up into individual components we have to download, convert and warp the map files.</p>
<p>We define three flows to do this which correspond to three different scripts.</p>
<pre><code>fetch = nixScript [relfile|fetch.py|] [[relfile|shell.nix|]]
          (\metadata -&gt; [ outParam, contentParam metadata ])

convertToGif = nixScript [relfile|convert_gif|] []
                (\dir -&gt; [ pathParam (IPItem dir), outParam ])

warp = nixScript [relfile|do_warp|] []
        (\dir -&gt; [ pathParam (IPItem dir), outParam ])</code></pre>
<p>Each script takes an individual input file and produces output in a directory specified by <code>funflow</code>.</p>
<p><code>fetch.py</code> is a python script whilst <code>convert_gif</code> and <code>do_warp</code> are bash scripts. We can treat them uniformly because of the <code>nix-shell</code> shebang.</p>
<p>These steps are all cached by default because they are external processes.</p>
<h2 id="step-3-merge-the-images-together">Step 3: Merge the images together</h2>
<p>In order to get a good looking result, we need to group together the processed images into groups of overlapping images. This time we will use a python script again invoked in a similar manner. The output is a directory of files which specify the groups, remember:</p>
<ol type="1">
<li>We have to be careful naming the files so that the names remain stable across compilation. In my original program the names were supplied by a counter but now they are the hash of the files which were used to create the group.</li>
<li>We have to use <code>splitDir</code> after creating the output to put each group file into it’s own store location so the next recompilation step will work.</li>
</ol>
<pre><code>mergeRasters = nixScript [relfile|merge-rasters.py|] [[relfile|merge-rasters.nix|]]
                (\rs -&gt; outParam : map contentParam rs )</code></pre>
<p>This command also relies on <code>merge-rasters.nix</code> which sets up the correct python environment to run the script.</p>
<h3 id="gotcha-2-mergedirs-can-also-defeat-caching">Gotcha 2: <code>mergeDirs</code> can also defeat caching</h3>
<p>The original implementation of this used <code>mergeDirs :: arr [Content File] (Content Dir)</code> in order to group together the files and pass a single directory to <code>merge-rasters.py</code>.</p>
<p>However, this suffers a similar problem to <code>listDirContents</code> as <code>mergeDirs</code> will create a new content store entry which contains all the files in the merge directories. The hash of this store location will then depend on the whole contents of the directory. In this case these file paths ended up in the output so it would cause the next steps to recompile even if nothing had changed.</p>
<p>In this case, we would prefer a “logical” group which groups the files together with a stable filename which wouldn’t affect caching.</p>
<p>The workaround for now was to use <code>splitDir</code> again to put each processed image into its own storage path and then pass each filename individually to <code>merge-rasters.py</code> rather than a directory as before.</p>
<h2 id="step-4-making-the-tiles">Step 4: Making the tiles</h2>
<p>Making the tiles is another straightforward step which takes each of the groups and makes the necessary tiles for that group.</p>
<pre><code>makeTiles = nixScript [relfile|make_tiles|] [] (\dir -&gt; [ contentParam dir, outParam, textParam &quot;16&quot; ])</code></pre>
<h3 id="gotcha-3-mergedirs-doesnt-merge-duplicate-files">Gotcha 3: <code>mergeDirs</code> doesn’t merge duplicate files</h3>
<p>Once we have made all the tiles we need to merge them all together. This is safe as we already ensured that they didn’t overlap each other. The problem is that <code>mergeDirs</code> will not merge duplicate files. The <code>make_tiles</code> step creates some unnecessary files which we don’t need but would cause <code>mergeDirs</code> to fail as they are contained in the output of each directory.</p>
<p>The solution was to write my own version of <code>mergeDirs</code> which checks to see whether a file already exists before trying to merge it. It would be more hygienic to ensure that the directories I was trying to merge were properly distinct but this worked well for this use case.</p>
<h2 id="step-5-creating-the-static-site">Step 5: Creating the static site</h2>
<p>Our final script is a python script which creates the static site displaying all the markers and the map tiles. It takes the output of processing all the images and the metainformation to produce a single html file.</p>
<pre><code>leaflet &lt;- step All &lt;&lt;&lt; makeLeaflet -&lt; ( script_dir, (merge_dir, meta_dir))</code></pre>
<p>The final step then merges together the static page and all the tiles. This is a nice bundle we can directly upload and serve our static site.</p>
<pre><code>mergeDirs -&lt; [leaflet, tiles]</code></pre>
<h2 id="putting-it-all-together">Putting it all together</h2>
<p>The complete flow is shown below:</p>
<pre><code>mainFlow :: SimpleFlow () (Content Dir)
mainFlow = proc () -&gt; do
  cwd &lt;- stepIO (const getCurrentDir) -&lt; ()
  script_dir &lt;- copyDirToStore -&lt; (DirectoryContent (cwd &lt;/&gt; [reldir|scripts/|]), Nothing)

	# Step 1
  meta_dir &lt;- step All &lt;&lt;&lt; scrape -&lt; (script_dir, ())
  keys &lt;- splitDir -&lt; meta_dir
	# Step 2
  maps &lt;- mapA (fetch) -&lt; [( script_dir, event) | event &lt;- keys]
  mapJpgs &lt;- mapA convertToGif -&lt; [(script_dir, m) | m &lt;- maps]
  merge_dir &lt;- mergeDirs&#39; &lt;&lt;&lt; mapA (step All) &lt;&lt;&lt; mapA warp -&lt; [(script_dir, jpg) | jpg &lt;- mapJpgs ]
  toMerge &lt;- splitDir -&lt; merge_dir
	# Step 3
  vrt_dir &lt;- step All &lt;&lt;&lt; mergeRasters -&lt; (script_dir, toMerge)
  merged_vrts &lt;- splitDir -&lt; vrt_dir
	# Step 4
  tiles &lt;- mergeDirs&#39; &lt;&lt;&lt; mapA (step All) &lt;&lt;&lt; mapA makeTiles -&lt; [(script_dir, vrt) | vrt &lt;- merged_vrts]

	# Step 5
  leaflet &lt;- step All &lt;&lt;&lt; makeLeaflet -&lt; ( script_dir, (merge_dir, meta_dir))

  mergeDirs -&lt; [leaflet, tiles]</code></pre>
<p>Once all the kinks are ironed out – it’s quite short but a very powerful specification which avoids a lot of redundant work being carried out.</p>
<h3 id="gotcha-4-copydirtostore-can-defeat-caching">Gotcha 4: <code>copyDirToStore</code> can defeat caching</h3>
<p>Using <code>copyDirToStore</code> seems much more convenient than copying each script into the store manually but it can again have confusing caching behaviour. The hash of the store location for <code>script_dir</code> depends on the whole <code>script_dir</code> directory. If you change any file in the directory then the hash of it will change. This means that all steps will recompile if you modify any script!</p>
<p>This is the reason for the <code>mergeFiles</code> call in <code>nixScriptX</code>. <code>mergeFiles</code> will take the necessary files from <code>script_dir</code> and put them into their own store directory. The hash of this directory will only depend on the files necessary for that step.</p>
<h2 id="running-the-flow">Running the flow</h2>
<p>The flow is run with the simple local runner. We pass in a location for the local store to the runner which is just a local directory in this case. The library has support for more complicated runners but I haven’t explored using those yet.</p>
<pre><code>main :: IO ()
main = do
    cwd &lt;- getCurrentDir
    r &lt;- withSimpleLocalRunner (cwd &lt;/&gt; [reldir|funflow-example/store|]) $ \run -&gt;
      run (mainFlow &gt;&gt;&gt; storePath) ()
    case r of
      Left err -&gt;
        putStrLn $ &quot;FAILED: &quot; ++ displayException err
      Right out -&gt; do
        putStrLn $ &quot;SUCCESS&quot;
        putStrLn $ toFilePath out</code></pre>
<h3 id="displaying-the-outpath">Displaying the outpath</h3>
<p>A nice feature of <code>nix-build</code> is that it displays the path of the final output in the nix store once the build has finished. This is possible to replicate using <code>funflow</code> after defining your own combinator. It would be good to put this in the standard library.</p>
<pre><code>storePath :: ArrowFlow eff ex arr =&gt; arr (Content Dir) (Path Abs Dir)
storePath = getFromStore return</code></pre>
<p>It means that we can run our flow and deploy the site in a single command given we have a script which performs the deployment given an output path.</p>
<p>Mine looks a bit like:</p>
<pre><code>#! /usr/bin/env nix-shell
#! nix-shell -i bash -p awscli
if [[ $# -eq 0 ]] ; then
     echo &#39;Must pass output directory&#39;
     exit 1
fi
aws s3 sync $1 s3://&lt;bucket-name&gt;</code></pre>
<p>Putting them together:</p>
<pre><code>cabal new-run | ./upload-s3</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>Once everything is set up properly, <code>funflow</code> is a joy to use. It abstracts beautifully away from the annoying problems of scheduling and caching leaving the core logic visible. An unfortunate consequence of the intensional store model is that debugging why a build step is not being cached can be very time consuming and fiddly. When I explain the problems I faced, they are obvious but each one required careful thought and reading the source code to understand the intricacies of each of the different operations.</p>
<p>It was also very pleasant to combine using <code>nix</code> and <code>funflow</code> rather than the suggested <code>docker</code> support.</p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="http://mpickering.github.io/maps.html">Map of orienteering maps</a></li>
<li><a href="https://github.com/mpickering/rg-map">Source code</a></li>
<li><a href="https://www.reddit.com/r/haskell/comments/9f7kq9/using_funflow_to_cache_a_nix_based_workflow/">Reddit comments</a></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Specifying how a plugin affects recompilation</title>
    <link href="http://mpickering.github.io/posts/2018-08-10-plugins-recompilation.html" />
    <id>http://mpickering.github.io/posts/2018-08-10-plugins-recompilation.html</id>
    <published>2018-08-10T00:00:00Z</published>
    <updated>2018-08-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Specifying how a plugin affects recompilation </h2>
<p class="text-muted">
    Posted on August 10, 2018
    
</p>

<p>Plugins have existed for a long time in GHC. The first plugins were implemented in <a href="http://blog.omega-prime.co.uk/2008/06/15/compiler-plugins-for-ghc-the-first-week/">2008</a> by Max Bolingbroke. They enabled users to modify the optimisation pipeline. They ran after desugaring and hence were called <a href="http://mpickering.github.io/ghc-docs/build-html/users_guide/extending_ghc.html#core-plugins-in-more-detail">“core” plugins</a>. Later, Adam Gundry implemented what I shall refer to as <a href="http://adam.gundry.co.uk/pub/typechecker-plugins/">“constraint solver” plugins</a> which allow users to provide custom solver logic to solve additional constraints. Recently, Boldizsár Németh has extended the number of extension points again with a set of plugins which can inspect and modify the syntax AST. Plugins can run after parsing, renaming or type checking and hence are called <a href="http://mpickering.github.io/ghc-docs/build-html/users_guide/extending_ghc.html#source-plugins">“source” plugins</a>.</p>
<p>The idea behind plugins was great - a user can extend the compiler in their own specific way without having to modify the source tree and rebuild the compiler from scratch. It is far more convenient to write a plugin than to use a custom compiler. However, if a user wants to use a plugin, they will find that every module where the plugin is enabled is always recompiled, even if the source code didn’t change at all. Why is this? Well, a plugin can do anything, it could read the value from a temperature sensor and insert the room temperature into the program. Thus, we would always need to recompile a module if the temperature reading changed as it would affect what our program did.</p>
<p>However, there are also “pure” plugins, whose output is only affected by the program which is passed as in input. For these plugins, if the source code doesn’t change then we don’t need to do any recompilation.</p>
<p>This post is about a new metadata field which I added to the <code>Plugin</code> data type which specifies how a plugin should affect recompilation. This feature will be present in GHC 8.6.</p>
<!--more-->
<h1 id="controlling-recompilation">Controlling Recompilation</h1>
<p>The <code>Plugin</code> data type is a record which contains a field for each of the different types of plugin. There is now also a new field <code>pluginRecompile</code> which specifies how the plugin should affect recompilation.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">data</span> <span class="dt">Plugin</span> {</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="ot">  installCoreToDos ::</span> <span class="dt">CorePlugin</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3">  ,<span class="ot"> tcPlugin ::</span> <span class="dt">TcPlugin</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4">  , parsedResultAction</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="ot">    ::</span> [<span class="dt">CommandLineOption</span>] <span class="ot">-&gt;</span> <span class="dt">ModSummary</span> <span class="ot">-&gt;</span> <span class="dt">HsParsedModule</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6">                                         <span class="ot">-&gt;</span> <span class="dt">Hsc</span> <span class="dt">HsParsedModule</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1-8" data-line-number="8">  <span class="fu">...</span> omitted fields</a>
<a class="sourceLine" id="cb1-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1-10" data-line-number="10">  ,<span class="ot"> pluginRecompile ::</span> [<span class="dt">CommandLineOpts</span>] <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">PluginRecompile</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11">}</a></code></pre></div>
<p>This function will be run during the recompilation check which happens at the start of every module compilation. It returns a value of the <code>PluginRecompile</code> data type.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">data</span> <span class="dt">PluginRecompile</span> <span class="fu">=</span> <span class="dt">PurePlugin</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">                     <span class="fu">|</span> <span class="dt">ImpurePlugin</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3">                     <span class="fu">|</span> <span class="dt">MaybeRecompile</span> <span class="dt">Fingerprint</span></a></code></pre></div>
<p>There are three different ways to specify how a plugin affects recompilation.</p>
<ol type="1">
<li><code>PurePlugin</code> which means that it doesn’t contribute anything to the recompilation check. We will only recompile a module if we would normally recompile it.</li>
<li><code>ImpurePlugin</code> which means that should always recompile a module. This is the default as it is backwards compatible.</li>
<li><code>MaybeRecompile</code>, we compute a <code>Fingerprint</code> which we add to the recompilation check to decide whether we should recompile.</li>
</ol>
<h2 id="library-functions">Library Functions</h2>
<p>The <code>Plugins</code> interface provides some library functions for common configurations.</p>
<p>We might want to use <code>impurePlugin</code> when our plugin injects some additional impure information into the program such as the result of reading a webpage.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="ot">impurePlugin ::</span> [<span class="dt">CommandLineOpts</span>] <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">PluginRecompile</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">impurePlugin _ <span class="fu">=</span> return <span class="dt">ImpurePlugin</span></a></code></pre></div>
<p>The <code>purePlugin</code> function is useful for static analysis tools which don’t modify the source program at all and just output information. Other plugins which modify the source program in a predictable manner such as the <code>ghc-typelits-natnormalise</code> plugin should also be marked as pure.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="ot">purePlugin ::</span> [<span class="dt">CommandLineOpts</span>] <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">PluginRecompile</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">purePlugin _args <span class="fu">=</span> return <span class="dt">NoForceRecompile</span></a></code></pre></div>
<p>If you have some options which affect the output of the plugin then you might want to use the <code>flagRecompile</code> option which causes recompilation if any of the plugin flags change.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="ot">flagRecompile ::</span> [<span class="dt">CommandLineOption</span>] <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">PluginRecompile</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">flagRecompile <span class="fu">=</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">  return <span class="fu">.</span> <span class="dt">MaybeRecompile</span> <span class="fu">.</span> fingerprintFingerprints</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">    <span class="fu">.</span> map fingerprintString <span class="fu">.</span> sort</a></code></pre></div>
<p>The nature of this interface is that it is sometimes necessary to be overly conservative when specifying recompilation behaviour. For example, you can’t decide on a per-module basis whether to recompile or not. Perhaps the interface could be extended with this information if user’s found it necessary.</p>
<h1 id="conclusion">Conclusion</h1>
<p>There is now a simple mechanism for controlling how plugins should affect recompilation. This solves one of the major problems that large scale usage of plugins has faced. Using a plugin on a 1000 module code base was impractical but now shouldn’t impose any additional inconvenience.</p>
<h1 id="related-links">Related Links</h1>
<ul>
<li><a href="http://mpickering.github.io/ghc-docs/build-html/users_guide/extending_ghc.html#controlling-recompilation">GHC User’s Guide</a></li>
<li><a href="https://www.reddit.com/r/haskell/comments/967o6k/specifying_how_a_plugin_affects_recompilation/">Reddit comments</a></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Reimplementing graphmod as a source plugin: graphmod-plugin</title>
    <link href="http://mpickering.github.io/posts/2018-08-09-source-plugin-graphmod.html" />
    <id>http://mpickering.github.io/posts/2018-08-09-source-plugin-graphmod.html</id>
    <published>2018-08-09T00:00:00Z</published>
    <updated>2018-08-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Reimplementing graphmod as a source plugin: graphmod-plugin </h2>
<p class="text-muted">
    Posted on August  9, 2018
    
</p>

<p>You may have heard about <a href="http://mpickering.github.io/ghc-docs/build-html/users_guide/extending_ghc.html#source-plugins">source plugins</a> by now. They allow you to modify and inspect the compiler’s intermediate representation. This is useful for extending GHC and performing static analysis of Haskell programs.</p>
<p>In order to test them out, I reimplemented the <a href="https://github.com/yav/graphmod"><code>graphmod</code></a> tool as a source plugin. <code>graphmod</code> generates a graph of the module structure of your package. Reimplementing it as a source plugin makes the implementation more robust. I implemented it as as a type checker plugin which runs after type checking has finished. The result: <a href="https://github.com/mpickering/graphmod-plugin"><code>graphmod-plugin</code></a></p>
<figure>
<img src="https://raw.githubusercontent.com/yav/graphmod/master/screenshots/aeson1.dot.png" alt="An example of the structure of the aeson package" /><figcaption>An example of the structure of the <code>aeson</code> package</figcaption>
</figure>
<!--more-->
<h1 id="architecture">Architecture</h1>
<p>The plugin runs once at the end of type checking for each module. Therefore, if we want to collate information about multiple modules, we must first serialise the information we want and then once all the modules have finished compiling collect all serialised files and process the information.</p>
<p>We will therefore first define a plugin which extracts all the import information from one module before defining the suitable executable which collects all the import information and produces the final output graph.</p>
<p><code>graphmod-plugin</code> consists of a library which exports the plugin and an executable which is then invoked to render the information. Here is how to directly use the two in tandem:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># Run the plugin on the source file</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="ex">ghc</span> -fplugin=GraphMod -fplugin-opt:GraphMod:/output/dir</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="co"># Collect the information which was produced</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="ex">graphmod-plugin</span> --indir /output/dir <span class="op">&gt;</span> modules.dot</a></code></pre></div>
<p>Once the dot file has been generated, you can use the normal graphviz utilities to render the file.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="fu">cat</span> modules.dot <span class="kw">|</span> <span class="ex">tred</span> <span class="kw">|</span> <span class="ex">dot</span> -Tpdf <span class="op">&gt;</span> modules.pdf</a></code></pre></div>
<p><code>tred</code> removes transitive edges from the graph before we render the graph as a pdf.</p>
<h1 id="the-plugin">The plugin</h1>
<p>A type checker plugin is a function of the following type:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="ot">sourcePlugin ::</span> [<span class="dt">CommandLineOpts</span>] <span class="ot">-&gt;</span> <span class="dt">ModSummary</span> <span class="ot">-&gt;</span> <span class="dt">TcGblEnv</span> <span class="ot">-&gt;</span> <span class="dt">TcM</span> <span class="dt">TcGblEnv</span></a></code></pre></div>
<p>The <code>TcGblEnv</code> is the output of the type checker, it contains all the type checked bindings in addition to lots of other useful information. We are interested in just the imports, these are located in the <code>tcg_rn_imports</code> field.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="ot">tcg_rn_imports ::</span> [<span class="dt">LImportDecl</span> <span class="dt">GhcRn</span>]</a></code></pre></div>
<p>An <code>LImportDecl GhcRn</code> is a data type which contains information about each import.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co">-- GHC data types</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="kw">type</span> <span class="dt">LImportDecl</span> pass <span class="fu">=</span> <span class="dt">Located</span> (<span class="dt">ImportDecl</span> pass)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="kw">data</span> <span class="dt">ImportDecl</span> pass</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">  <span class="fu">=</span> <span class="dt">ImportDecl</span> {</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="ot">      ideclExt       ::</span> <span class="dt">XCImportDecl</span> pass,</a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="ot">      ideclSourceSrc ::</span> <span class="dt">SourceText</span>,</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="ot">      ideclName      ::</span> <span class="dt">Located</span> <span class="dt">ModuleName</span>, <span class="co">-- ^ Module name.</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"><span class="ot">      ideclPkgQual   ::</span> <span class="dt">Maybe</span> <span class="dt">StringLiteral</span>,  <span class="co">-- ^ Package qualifier.</span></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="ot">      ideclSource    ::</span> <span class="dt">Bool</span>,          <span class="co">-- ^ True &lt;=&gt; {-\# SOURCE \#-} import</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="ot">      ideclSafe      ::</span> <span class="dt">Bool</span>,          <span class="co">-- ^ True =&gt; safe import</span></a>
<a class="sourceLine" id="cb5-12" data-line-number="12"><span class="ot">      ideclQualified ::</span> <span class="dt">Bool</span>,          <span class="co">-- ^ True =&gt; qualified</span></a>
<a class="sourceLine" id="cb5-13" data-line-number="13"><span class="ot">      ideclImplicit  ::</span> <span class="dt">Bool</span>,          <span class="co">-- ^ True =&gt; implicit import (of Prel</span></a>
<a class="sourceLine" id="cb5-14" data-line-number="14">ude)</a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="ot">      ideclAs        ::</span> <span class="dt">Maybe</span> (<span class="dt">Located</span> <span class="dt">ModuleName</span>),  <span class="co">-- ^ as Module</span></a>
<a class="sourceLine" id="cb5-16" data-line-number="16"><span class="ot">      ideclHiding    ::</span> <span class="dt">Maybe</span> (<span class="dt">Bool</span>, <span class="dt">Located</span> [<span class="dt">LIE</span> pass])</a>
<a class="sourceLine" id="cb5-17" data-line-number="17">                                       <span class="co">-- ^ (True =&gt; hiding, names)</span></a>
<a class="sourceLine" id="cb5-18" data-line-number="18">    }</a></code></pre></div>
<p>Along with the module name, there is lots of meta information about other aspects of the import such as whether it was qualified and so on. Our plugin will take this information and convert it into the format expected by the existing <code>graphmod</code> library.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="ot"># Graphmod data types</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw">data</span> <span class="dt">Import</span> <span class="fu">=</span> <span class="dt">Import</span> {<span class="ot"> impMod ::</span> <span class="dt">ModName</span>,<span class="ot"> impType ::</span> <span class="dt">ImpType</span> }</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="kw">data</span> <span class="dt">ImpType</span> <span class="fu">=</span> <span class="dt">NormalImp</span> <span class="fu">|</span> <span class="dt">SourceImp</span></a></code></pre></div>
<p>The <code>graphmod</code> <code>Import</code> data type is a simplified version of <code>ImportDecl</code>. It’s straightforward to extract the information we need. Notice how much simpler this approach is than the approach taken in the original library which uses a lexer to try to identify textually the position of the imports.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="ot">convertImport ::</span> <span class="dt">ImportDecl</span> <span class="dt">GhcRn</span> <span class="ot">-&gt;</span> <span class="dt">GraphMod.Import</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2">convertImport (<span class="dt">ImportDecl</span>{<span class="fu">..</span>}) <span class="fu">=</span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">  <span class="dt">GraphMod.Import</span> { impMod <span class="fu">=</span> convertModName (ideclName)</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">                  , impType <span class="fu">=</span> <span class="kw">if</span> ideclSource</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">                                <span class="kw">then</span> <span class="dt">GraphMod.SourceImp</span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6">                                <span class="kw">else</span> <span class="dt">GraphMod.NormalImp</span></a>
<a class="sourceLine" id="cb7-7" data-line-number="7">                  }</a>
<a class="sourceLine" id="cb7-8" data-line-number="8"></a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="ot">convertModName ::</span> <span class="dt">Located</span> <span class="dt">ModuleName</span> <span class="ot">-&gt;</span> <span class="dt">GraphMod.ModName</span></a>
<a class="sourceLine" id="cb7-10" data-line-number="10">convertModName (<span class="dt">L</span> _ mn) <span class="fu">=</span> GraphMod.splitModName (moduleNameString mn)</a></code></pre></div>
<p>Notice that it is also possible to extend the <code>GraphMod.Import</code> data type to contain new information easily. In the previous implementation this would be much more effort as the lexing approach is fragile.</p>
<h1 id="serialisation">Serialisation</h1>
<p>Once we have gathered this information we need to serialise it and write it to disk so that once we have compiled all the modules we can deserialise it and render the final graph.</p>
<p>As we are using GHC, we can use the same serialisation machinery as GHC uses to write interface files. Of course, you are free to use whatever serialisation library you like but there are already instances defined for GHC specific types. We won’t need any of them in this example but they can be useful. The <code>writeBinary</code> function takes a value serialisable by the <code>GHC.Binary</code> class and writes it to the file.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">import</span> <span class="dt">Binary</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="ot">initBinMemSize ::</span> <span class="dt">Int</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">initBinMemSize <span class="fu">=</span> <span class="dv">1024</span> <span class="fu">*</span> <span class="dv">1024</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"></a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="ot">writeBinary ::</span> <span class="dt">Binary</span> a <span class="ot">=&gt;</span> FilePath <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">writeBinary path payload <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb8-8" data-line-number="8">  bh <span class="ot">&lt;-</span> openBinMem initBinMemSize</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">  put_ bh payload</a>
<a class="sourceLine" id="cb8-10" data-line-number="10">  writeBinMem bh path</a></code></pre></div>
<p>We also needed to write some simple <code>Binary</code> instances by hand in order to do the serialisation.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">instance</span> <span class="dt">Binary</span> <span class="dt">GraphMod.Import</span> <span class="kw">where</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">  put_ bh (<span class="dt">GraphMod.Import</span> mn ip) <span class="fu">=</span> put_ bh mn <span class="fu">&gt;&gt;</span> put_ bh ip</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">  get bh <span class="fu">=</span> <span class="dt">GraphMod.Import</span> <span class="fu">&lt;$&gt;</span> get bh <span class="fu">&lt;*&gt;</span> get bh</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="kw">instance</span> <span class="dt">Binary</span> <span class="dt">GraphMod.ImpType</span> <span class="kw">where</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5">  put_ bh c <span class="fu">=</span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6">    <span class="kw">case</span> c <span class="kw">of</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7">      <span class="dt">GraphMod.NormalImp</span> <span class="ot">-&gt;</span> putByte bh <span class="dv">0</span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8">      <span class="dt">GraphMod.SourceImp</span> <span class="ot">-&gt;</span> putByte bh <span class="dv">1</span></a>
<a class="sourceLine" id="cb9-9" data-line-number="9">  get bh <span class="fu">=</span> getByte bh  <span class="fu">&gt;&gt;=</span> return <span class="fu">.</span> \<span class="kw">case</span></a>
<a class="sourceLine" id="cb9-10" data-line-number="10">                      <span class="dv">0</span> <span class="ot">-&gt;</span> <span class="dt">GraphMod.NormalImp</span></a>
<a class="sourceLine" id="cb9-11" data-line-number="11">                      <span class="dv">1</span> <span class="ot">-&gt;</span> <span class="dt">GraphMod.SourceImp</span></a>
<a class="sourceLine" id="cb9-12" data-line-number="12">                      _ <span class="ot">-&gt;</span> error <span class="st">&quot;Binary:GraphMod&quot;</span></a></code></pre></div>
<h1 id="plugin-description">Plugin Description</h1>
<p>Once we have these parts, we can assemble them into the final plugin. We first get the imports out of <code>tcg_rn_imports</code> and then convert them using <code>convertImport</code>. We then write this information to a uniquely named file in the output directory which is passed as an argument to the plugin.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co">-- The main plugin function, it collects and serialises the import</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="co">-- information for a module.</span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="ot">install ::</span> [<span class="dt">CommandLineOption</span>] <span class="ot">-&gt;</span> <span class="dt">ModSummary</span> <span class="ot">-&gt;</span> <span class="dt">TcGblEnv</span> <span class="ot">-&gt;</span> <span class="dt">TcM</span> <span class="dt">TcGblEnv</span></a>
<a class="sourceLine" id="cb10-4" data-line-number="4">install opts ms tc_gbl <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">    <span class="kw">let</span> imps <span class="fu">=</span> tcg_rn_imports tc_gbl</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">        gm_imps <span class="fu">=</span> map (convertImport <span class="fu">.</span> unLoc) imps</a>
<a class="sourceLine" id="cb10-7" data-line-number="7">        outdir <span class="fu">=</span> mkOutdir opts</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">        path <span class="fu">=</span> mkPath outdir (ms_mod ms)</a>
<a class="sourceLine" id="cb10-9" data-line-number="9">        gm_modname <span class="fu">=</span> getModName ms</a>
<a class="sourceLine" id="cb10-10" data-line-number="10">    liftIO <span class="fu">$</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb10-11" data-line-number="11">      createDirectoryIfMissing <span class="dt">False</span> outdir</a>
<a class="sourceLine" id="cb10-12" data-line-number="12">      writeBinary path (gm_modname, gm_imps)</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">    return tc_gbl</a></code></pre></div>
<p><code>mkPath</code> tries to come up with a unique name for a module by using the <code>moduleUnitId</code>. The file name doesn’t matter particularly as long as it’s unique. We could instead write this information to a database or to a file handle. Writing to disk is just a convenient method of serialisation.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="ot">mkPath ::</span> FilePath <span class="ot">-&gt;</span> <span class="dt">Module</span> <span class="ot">-&gt;</span> FilePath</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">mkPath fp m</a>
<a class="sourceLine" id="cb11-3" data-line-number="3">  <span class="fu">=</span> fp <span class="fu">&lt;/&gt;</span> (moduleNameString (moduleName m) <span class="fu">++</span> (show (moduleUnitId m)))</a></code></pre></div>
<p>Then, we define the plugin by making a definition called <code>plugin</code> and overriding the <code>typeCheckResultAction</code> field and the <code>pluginRecompile</code> field. <code>purePlugin</code> means that the result of our plugin only depends on the contents of the source file rather than any external information. This means that we don’t need to recompile the module every time just because we are using a plugin.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co">-- Installing the plugin</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="ot">plugin ::</span> <span class="dt">Plugin</span></a>
<a class="sourceLine" id="cb12-3" data-line-number="3">plugin <span class="fu">=</span> defaultPlugin  {</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">  typeCheckResultAction <span class="fu">=</span> install</a>
<a class="sourceLine" id="cb12-5" data-line-number="5">  , pluginRecompile <span class="fu">=</span> purePlugin</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">}</a></code></pre></div>
<p>Now that our module exports an identifier of type <code>Plugin</code> called <code>plugin</code> we are finished defining the plugin part of the project.</p>
<h1 id="the-finaliser">The finaliser</h1>
<p>Once all the modules have finished compiling. They will have written their information to a file in a certain directory that we can now inspect to create the dot graph.</p>
<p>We define an executable to do this. The executable takes the directory of the files as an argument, reads all the files and then processes them to produce the graph.</p>
<p>In the <code>collectImports</code> function, we first read the directory from a command line argument. Then we find all the files in this directory and read their contents into memory. We use the helper function <code>readImports</code> which uses functions from the <code>Binary</code> module to read the serialised files. Finally, we build the graph using all the import information and then pass the graph we have built to the existing <code>graphmod</code> backend.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode haskell"><code class="sourceCode haskell"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="ot">collectImports ::</span> <span class="dt">IO</span> ()</a>
<a class="sourceLine" id="cb13-2" data-line-number="2">collectImports <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">  raw_opts <span class="ot">&lt;-</span> getArgs</a>
<a class="sourceLine" id="cb13-4" data-line-number="4">  <span class="kw">let</span> (fs, _ms, _errs) <span class="fu">=</span> getOpt <span class="dt">Permute</span> options raw_opts</a>
<a class="sourceLine" id="cb13-5" data-line-number="5">      opts <span class="fu">=</span> foldr (<span class="fu">$</span>) default_opts fs</a>
<a class="sourceLine" id="cb13-6" data-line-number="6"></a>
<a class="sourceLine" id="cb13-7" data-line-number="7">      outdir <span class="fu">=</span> inputDir opts</a>
<a class="sourceLine" id="cb13-8" data-line-number="8">  files <span class="ot">&lt;-</span> listDirectory outdir</a>
<a class="sourceLine" id="cb13-9" data-line-number="9"></a>
<a class="sourceLine" id="cb13-10" data-line-number="10">  usages <span class="ot">&lt;-</span> mapM (readImports outdir) files</a>
<a class="sourceLine" id="cb13-11" data-line-number="11"></a>
<a class="sourceLine" id="cb13-12" data-line-number="12">  <span class="kw">let</span> graph <span class="fu">=</span> buildGraph opts usages</a>
<a class="sourceLine" id="cb13-13" data-line-number="13">  putStr (GraphMod.make_dot opts graph)</a>
<a class="sourceLine" id="cb13-14" data-line-number="14"></a>
<a class="sourceLine" id="cb13-15" data-line-number="15"></a>
<a class="sourceLine" id="cb13-16" data-line-number="16"><span class="ot">readImports ::</span> FilePath <span class="ot">-&gt;</span> FilePath <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">Payload</span></a>
<a class="sourceLine" id="cb13-17" data-line-number="17">readImports outdir fp <span class="fu">=</span> <span class="kw">do</span></a>
<a class="sourceLine" id="cb13-18" data-line-number="18">  readBinMem (outdir <span class="fu">&lt;/&gt;</span> fp) <span class="fu">&gt;&gt;=</span> get</a></code></pre></div>
<p>The <code>buildGraph</code> function builds an in memory representation of the module graph. There is a node for each module and an edge between modules if one imports the other. We finally mimic the original <code>graphmod</code> tool and output the representation of the graph on <code>stdout</code>. This can then be piped to <code>dot</code> in order to render the graph.</p>
<h1 id="running-the-plugin-with-nix">Running the plugin with nix</h1>
<p>By far the most convenient way to run the plugin is with nix. This gets around the problem of having to run the finaliser after compiling the plugin. We use the <a href="http://mpickering.github.io/posts/2018-06-24-haskell-nix-plugins.html"><code>haskell-nix-plugin</code></a> infrastructure in order to do this.</p>
<p>The information required to run the plugin consists of information about the plugin package but also an additional, optional, final phase which runs after the module has finished compiling.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="ex">graphmod</span> =</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">  <span class="kw">{</span> <span class="ex">pluginPackage</span> = hp.graphmod-plugin<span class="kw">;</span></a>
<a class="sourceLine" id="cb14-3" data-line-number="3">    <span class="ex">pluginName</span> = <span class="st">&quot;GraphMod&quot;</span><span class="kw">;</span></a>
<a class="sourceLine" id="cb14-4" data-line-number="4">    <span class="ex">pluginOpts</span> = (out-path: [<span class="st">&quot;</span><span class="va">${out-</span>path<span class="va">}</span><span class="st">/output&quot;</span>]);</a>
<a class="sourceLine" id="cb14-5" data-line-number="5">    <span class="ex">pluginDepends</span> = [ nixpkgs.graphviz ]<span class="kw">;</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6">    <span class="ex">finalPhase</span> = out-path: <span class="st">&#39;&#39;</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7">      <span class="ex">graphmod-plugin</span> --indir <span class="va">${out-</span>path<span class="va">}</span>/output <span class="op">&gt;</span> <span class="va">${out-</span>path<span class="va">}</span>/out.dot</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">      <span class="fu">cat</span> <span class="va">${out-</span>path<span class="va">}</span>/out.dot <span class="kw">|</span> <span class="ex">tred</span> <span class="kw">|</span> <span class="ex">dot</span> -Gdpi=600 -Tpng <span class="op">&gt;</span> <span class="va">${out-</span>path<span class="va">}</span>/modules.png</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">      <span class="st">&#39;&#39;</span>; <span class="kw">}</span> ;</a></code></pre></div>
<p>I will add this definition to the <code>plugins.nix</code> file in <code>haskell-nix-plugin</code> once ghc-8.6.1 is released.</p>
<p>We then would use the <code>addPlugin</code> function in order to run the plugin on a package. In order to get the module graph we inspect the <code>GraphMod</code> output.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">(</span><span class="ex">addPlugin</span> graphmod hp.aeson<span class="kw">)</span><span class="ex">.GraphMod</span></a></code></pre></div>
<p>Running this script on <code>aeson</code> produces <a href="https://i.imgur.com/baiyyuc.jpg">this</a> quite large image which shows the whole module graph.</p>
<p>A complete example <code>default.nix</code> can be found in the <a href="https://github.com/mpickering/graphmod-plugin/blob/master/default.nix">repo</a>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>We have described one way in which one can structure a plugin. There are probably other ways but this seems ergnomic and convenient. Hopefully others will find this quite detailed summary and reference code useful to build upon.</p>
<p>Writing plugins is quite similar to modifying GHC itself so if you need help, the best place to ask is either on the <a href="https://mail.haskell.org/mailman/listinfo/ghc-devs"><code>ghc-devs</code> mailing list</a> or on #ghc on freenode.</p>
<h1 id="related-links">Related Links</h1>
<ul>
<li><a href="https://github.com/mpickering/graphmod-plugin"><code>graphmod-plugin</code></a></li>
<li><a href="https://www.reddit.com/r/haskell/comments/95r8uj/reimplementing_graphmod_as_a_source_plugin/">Reddit comments</a></li>
</ul>
]]></summary>
</entry>
<entry>
    <title>Nix scaffolding for running Haskell plugins</title>
    <link href="http://mpickering.github.io/posts/2018-06-24-haskell-nix-plugins.html" />
    <id>http://mpickering.github.io/posts/2018-06-24-haskell-nix-plugins.html</id>
    <published>2018-06-24T00:00:00Z</published>
    <updated>2018-06-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Nix scaffolding for running Haskell plugins </h2>
<p class="text-muted">
    Posted on June 24, 2018
    
</p>

<p>I’ve been all about writing <a href="http://mpickering.github.io/posts/2018-06-11-source-plugins.html">source plugins</a> recently but have been dissatisfied with how rough it is to use them practically. In particular, I am writing plugins which don’t change the semantics of my programs but are useful for debugging. I only sometimes want to run them and don’t want them to appear as dependencies at all on Hackage. It needs to be easy to apply them to my own and other people’s packages.</p>
<p>Of course, the solution was to leverage my knowledge of nix to wrap up everything into a nice interface. The key to the interface is a new function <code>haskell.lib.addPlugin</code> which augments an existing package with a plugin.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="ex">addPlugin</span> dump-core-plugin either</a></code></pre></div>
<p>This invocation will now also output an HTML representation of the core program of the <code>either</code> package by using the <code>dump-core</code> plugin.</p>
<p>This post will explain this interface in more detail but will not get into the gritty implementation details. The implementation can be found in the <a href="https://github.com/mpickering/haskell-nix-plugin"><code>haskell-nix-plugin</code></a> repo.</p>
<!--more-->
<h1 id="two-uses-of-plugins">Two uses of plugins</h1>
<p>There are two kinds of plugins:</p>
<ol type="1">
<li>A plugin which modify your program so should always run. For example, the <a href="https://hackage.haskell.org/package/ghc-typelits-natnormalise"><code>ghc-typelits-natnormalise</code></a> plugin which solves constraints containing type level numbers.</li>
<li>A plugin which collects information or debugging information which is optional. For example, the <a href="https://hackage.haskell.org/package/dump-core"><code>dump-core</code></a> plugin which outputs an HTML rendering of the core of your program.</li>
</ol>
<p>Even though you only sometimes want to run plugins in the second category, the convenient way to involves several steps:</p>
<ol type="1">
<li>Add the plugin package to your <code>build-depends</code>.</li>
<li>Pass a specific option <code>-fplugin=DumpCore</code> by modifying <code>ghc-options</code>.</li>
</ol>
<p>If you want to package your library correctly, you then need to hide this information behind a cabal flag. However, this is still undesirable as a package like <code>dump-core</code> is only going to be used by developers but the flag now appears in the public interface. Further to this, I can’t run my plugin on someone else’s package without modifying the cabal file.</p>
<p>What we really want is a way to take an existing package and to augment it to run the plugin. In order to do this, we define a function <code>addPlugin</code> which takes a plugin and a package as an argument and then compiles the package whilst running the plugin. For example, if we want to inspect the core of the <code>either</code> package, we could specify this like so.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="ex">addPlugin</span> dump-core-plugin either</a></code></pre></div>
<p>If we then build this modified package, there will be a new output which has the same name as the plugin which contains the output of the plugin. So in this case, we will find the relevant HTML by inspecting the <code>DumpCore</code> attribute. It will also be symlinked to <code>result-DumpCore</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="ex">either-core</span> = (addPlugin dump-core-plugin either)<span class="ex">.DumpCore</span></a></code></pre></div>
<p>There are three new elements to the nixpkgs API.</p>
<ol type="1">
<li>A new function <code>haskell.lib.addPlugin</code> which adds a plugin to a package.</li>
<li>A new attribute <code>haskell.plugins</code> which is parameterised by a Haskell package set and contains a set of plugins.</li>
<li>A new <code>with*</code> function, <code>haskellPackages.withPlugin</code> which takes a function expecting two arguments, the first being a set of plugins for that package set and the second being a list of packages for that package set. The result of the function should be a Haskell package.</li>
</ol>
<h2 id="the-plugin-set">The plugin set</h2>
<p>The <code>haskell.plugins</code> attribute is a set of plugins parameterised by a normal Haskell package set. It is designed in this manner so the same plugin definitions can be used with different compilers.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="ex">hp</span>:</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="kw">{</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="ex">dump-core</span> = { ... <span class="kw">}</span>;</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="ex">graphmod-plugin</span> = { ... };</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">}</a></code></pre></div>
<p>Each attribute is a different plugin which we might want to use with our program.</p>
<h2 id="a-plugin">A plugin</h2>
<p>A plugin is a Haskell package which provides the plugin with four additional attributes which describe how to run it. For example, here is the definition for the <code>dump-core</code> plugin.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="ex">dump-core</span> = { pluginPackage = hp.dump-core <span class="kw">;</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">              <span class="ex">pluginName</span> = <span class="st">&quot;DumpCore&quot;</span><span class="kw">;</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">              <span class="ex">pluginOpts</span> = (out-path: [out-path]);</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">              <span class="ex">pluginDepends</span> = []<span class="kw">;</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5">              <span class="ex">finalPhase</span> = _: <span class="st">&quot;&quot;</span><span class="kw">;</span> } ;</a></code></pre></div>
<dl>
<dt><code>pluginPackage</code></dt>
<dd>The Haskell package which provides the plugin.
</dd>
<dt><code>pluginName</code></dt>
<dd>The module name where the plugin is defined.
</dd>
<dt><code>pluginOpts</code></dt>
<dd>Additional options to pass to the plugin. The path where it places its output is passed as an argument.
</dd>
<dt><code>pluginDepends</code></dt>
<dd>Any additional system dependencies the plugin needs for the finalPhase.
</dd>
<dt><code>finalPhase</code></dt>
<dd>An action to run in the <code>postBuild</code> phase, after the plugin has run. The output directory is passed as an argument.
</dd>
</dl>
<p>In most cases, <code>pluginDepends</code> and <code>finalPhase</code> can be omitted (they then take these default values) but they are useful for when a plugin emits information as it compiles each module which is then summarised at the end.</p>
<p>An example of this architecture is the <a href="https://github.com/mpickering/graphmod-plugin"><code>graphmod-plugin</code></a>. As each module is compiled, the import information is serialised. Then, at the end we read all the serialised files and create a dot graph of the module import structure. Here is how we specify the final phase of the plugin:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode nix"><code class="sourceCode bash"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="ex">graphmod</span> = { pluginPackage = hp.graphmod-plugin<span class="kw">;</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2">             <span class="ex">pluginName</span> = <span class="st">&quot;GraphMod&quot;</span><span class="kw">;</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">             <span class="ex">pluginOpts</span> = (out-path: [<span class="st">&quot;</span><span class="va">${out-</span>path<span class="va">}</span><span class="st">/output&quot;</span>]);</a>
<a class="sourceLine" id="cb6-4" data-line-number="4">             <span class="ex">pluginDepends</span> = [ nixpkgs.graphviz ]<span class="kw">;</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">             <span class="ex">finalPhase</span> = out-path: <span class="st">&#39;&#39;</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6">                <span class="ex">graphmod-plugin</span> --indir <span class="va">${out-</span>path<span class="va">}</span>/output <span class="op">&gt;</span> <span class="va">${out-</span>path<span class="va">}</span>/out.dot</a>
<a class="sourceLine" id="cb6-7" data-line-number="7">                <span class="fu">cat</span> <span class="va">${out-</span>path<span class="va">}</span>/out.dot <span class="kw">|</span> <span class="ex">tred</span> <span class="kw">|</span> <span class="ex">dot</span> -Tpdf <span class="op">&gt;</span> <span class="va">${out-</span>path<span class="va">}</span>/modules.pdf</a>
<a class="sourceLine" id="cb6-8" data-line-number="8">              <span class="st">&#39;&#39;</span>; } ;</a></code></pre></div>
<p>The first three fields are standard, however we now populate the final two arguments as well. We firstly add a dependency on <code>graphviz</code> which we will use to render the module graph and then specify the invocations needed to firstly summarise and then render the information.</p>
<p>In this architecture, the plugin package provides a library interface which exposes the plugin and an executable which is invoked to collect the information output by the plugin. This is what the call to <code>graphmod-plugin</code> achieves.</p>
<h2 id="withplugin"><code>withPlugin</code></h2>
<p>We also provide the <code>withPlugin</code> attribute which supplies both the plugins and packages already applied to a specific package set. The reason for this is that <strong>a plugin and a package must be both compiled by the same compiler</strong>. Thus, unrestricted usage of <code>addPlugin</code> can lead to confusing errors if the plugin and package are compiled with different compilers. The <code>withPlugin</code> attribute ensures that the versions align correctly.</p>
<pre><code>core-either =
  haskellPackages.withPlugin
    (plugins: packages: addPlugin plugins.dump-core packages.either)</code></pre>
<h2 id="how-can-i-use-it">How can I use it?</h2>
<p>This infrastructure is provided as an overlay. Install the overlay as you would normally, one suggested method can be see in the <a href="https://github.com/mpickering/haskell-nix-plugin/blob/master/example.nix"><code>example.nix</code></a> file.</p>
<pre><code>let
  plugin-overlay-git = builtins.fetchGit
    { url = https://github.com/mpickering/haskell-nix-plugin.git;}  ;
  plugin-overlay = import &quot;${plugin-overlay-git}/overlay.nix&quot;;
  nixpkgs = import &lt;nixpkgs&gt; { overlays = [plugin-overlay]; };
in ...</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>So far, I have not package many plugins in this manner but as source plugins are released in GHC 8.6 I expect to want to use plugins more and more regularly.</p>
<h3 id="related-links">Related Links</h3>
]]></summary>
</entry>
<entry>
    <title>Fixing the missing `ar` error with a development build of GHC (on NixOS)</title>
    <link href="http://mpickering.github.io/posts/2018-06-21-binutils-unwrapped.html" />
    <id>http://mpickering.github.io/posts/2018-06-21-binutils-unwrapped.html</id>
    <published>2018-06-21T00:00:00Z</published>
    <updated>2018-06-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h2> Fixing the missing `ar` error with a development build of GHC (on NixOS) </h2>
<p class="text-muted">
    Posted on June 21, 2018
    
</p>

<p>On NixOS, if you build GHC from source using Make or hadrian and try to use it with cabal then you will be greeted with the following error:</p>
<pre><code>cabal: The program &#39;ar&#39; is required but it could not be found.</code></pre>
<p>The way to fix this problem is to run cabal in an environment with the <code>binutils-unwrapped</code> package available. You can then use cabal as normal.</p>
<pre><code>nix-shell -p binutils-unwrapped</code></pre>
]]></summary>
</entry>

</feed>
