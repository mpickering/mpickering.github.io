<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>mpickering - Using funflow to cache a nix based workflow</title>
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link href="http://fonts.googleapis.com/css?family=Vollkorn" rel="stylesheet" type="text/css">
    </head>
    <body>
        <div class="container">
          <div class="row">
            <div class="col-sm-auto">
              <ul class="nav flex-column">
              <li class="nav-item">
                <a href="../">Home</a>
              </li>
              <li class="nav-item">
                <a href="../about.html">About</a> <br>
              </li>
              <li>
                <a href="../publications.html">Publications</a>
              </li>
              <li>
                <a href="../plugins.html">Plugins</a>
              </li>
              <li>
                <a href="../eventlog2html">eventlog2html</a>
              </li>
              <li>
                <a href="../ide/index.html">
                <img style="height: 0.8em; margin-right: 2px;" src="../ide/images/haskell-logo.svg" /></span>
                IDE 2020</a>
              </li>
          <!---
              <li>
                <a href="/bristol2020.html">Bristol 2020</a>
              </li>
              <li>
                <a href="https://andreaspk.github.io/ghc-week">GHC Week</a>
              </li>
          --->
              <li>
                <a href="../maps.html">Maps</a>
              </li>
              <li>
                <a href="../hurstwood.html">Hurstwood TrailO</a>
              </li>
              <li class="nav-item">
                <a href="../archive.html">Archive</a> <br>
              </li>
              <li>
                <a href="../atom.xml">Feed</a>
              </li>
              </ul>
            </div>
          <div class="col-md">

            <div id="content">
              <h2> Using funflow to cache a nix based workflow </h2>
<p class="text-muted">
    Posted on September 12, 2018
    
</p>

<p>My latest project has been to plot a <a href="http://mpickering.github.io/maps.html">map of orienteering maps</a> in the UK. This post explains the technical aspects behind the project and primarily the use of <a href="https://hackage.haskell.org/package/funflow"><code>funflow</code></a> to turn my assortment of scripts into into a resumable workflow.</p>
<p>There was nothing wrong with my ad-hoc python and bash scripts but they downloaded and regenerated the whole output every time. The whole generation takes about 2 hours so it’s desirable to only recompute the necessary portions. This is where <code>funflow</code> comes in, by stringing together these scripts in their DSL, you get caching for free. The workflow is also highly parallelisable so in the future I could distribute the work across multiple machines if necessary.</p>
<p>The code for the project can be found <a href="https://github.com/mpickering/rg-map">here</a>.</p>
<p><img src="https://i.imgur.com/NVLui01.png" style="width: 50%; margin: auto; display: block" /></p>
<!--more-->
<h2 id="funflow"><code>funflow</code></h2>
<p>There are already two blog posts introducing the concepts of <code>funflow</code>.</p>
<ol type="1">
<li><a href="https://www.tweag.io/posts/2018-04-25-funflow.html">Funflow: Typed Resumable Workflows</a></li>
<li><a href="https://www.tweag.io/posts/2018-07-10-funflow-make.html">Funflow Example: Emulating Make</a></li>
</ol>
<p>The main idea is that you specify your workflow (usually a sequence of external scripts) using a DSL and then <code>funflow</code> will automatically cache and schedule the steps.</p>
<p>My primary motivation for using <code>funflow</code> was the automatic caching. The store is content addressed which means that the location for each file in the store depends on its contents. <code>funflow</code> performs two different types of caching.</p>
<ol type="1">
<li>Input-based caching: A flow will only be executed once for each set of inputs.</li>
<li>Output-based caching: If multiple different steps produce the same output then it will only be stored once in the store. Further steps will not be recomputed.</li>
</ol>
<p>The lack of output-based caching is one of the big missing features of nix which makes it unsuitable for this task. A content-addressed store where the address depends on the contents of the file is sometimes known as an <strong>intensional</strong> store. Nix’s store model is <strong>extensional</strong> as the store hash only depends on the inputs to the build.</p>
<p>An intensional store relies on the program producing deterministic output hashes. It can be quite difficult to track down why a step is not being cached when you are relying on the output’s being identified in the store.</p>
<h2 id="high-level-architecture">High-level architecture</h2>
<p>There are two outputs to the project.</p>
<ol type="1">
<li>A folder of map tiles rendered at different resolutions.</li>
<li>A HTML page which contains the javascript to display the map and markers.</li>
</ol>
<p>This folder is then uploaded to online storage and served as a static site.</p>
<p>The processing pipeline is as follows:</p>
<ol type="1">
<li>Find all the maps with location information from <a href="http://www.routegadget.co.uk/">routegadget.co.uk</a>.</li>
<li>Download the metainformation and map image for each map.</li>
<li>Convert the maps to a common image format.</li>
<li>Reproject the maps to remove any rotation.</li>
<li>Merge overlapping maps into groups.</li>
<li>Generate tiles at all the different resolutions.</li>
<li>Combine all the tiles groups together.</li>
<li>Generate the website with the map and location markers.</li>
</ol>
<p>As can be seen, the workflow is firstly highly parallelisable as much of the processing pipeline happens independently of other steps. However, the main goal is to avoid computing the tiles as much as possible as this is the step which takes by far the longest. At the time of writing there are about 500 maps to process. In general, there are about 5-10 maps added each week. Only recomputing the changed portions of the map saves a lot of time.</p>
<h2 id="implementation-using-funflow">Implementation using <code>funflow</code></h2>
<p>In theory, this is a perfect application for <code>funflow</code> but in order to achieve the perfect caching behaviour I had to rearchitecture several parts of the application.</p>
<h3 id="using-nix-scripts">Using nix scripts</h3>
<p>The recommended way to use <code>funflow</code> is to run each step of the flow in a docker container. I didn’t want to do this was my scripts already declared the correct environment to run in by using the <a href="http://iam.travishartwell.net/2015/06/17/nix-shell-shebang/"><code>nix-shell</code> shebang</a>.</p>
<pre><code>#! /usr/bin/env nix-shell
#! nix-shell -i bash -p gdal</code></pre>
<p>By placing these two lines at the top of the file, the script will be run using the <code>bash</code> interpreter with the <code>gdal</code> package available. This is more lightweight and flexible than using a docker image as I don’t have to regenerate a new docker image any time I make a change.</p>
<p>However, there is no native support for running these kinds of scripts built into <code>funflow</code>. It was easy enough to define my own function in order to run these kinds of scripts using the <code>external'</code> primitive.</p>
<p><code>nixScript</code> takes a boolean parameter indicating whether the script is pure and should be cached. The name of the script to run, the names of any files the script depends on and finally a function which supplies any additional arguments to the script.</p>
<pre><code>nixScriptX :: ArrowFlow eff ex arr =&gt; Bool
                                   -&gt; Path Rel File
                                   -&gt; [Path Rel File]
                                   -&gt; (a -&gt; [Param])
                                   -&gt; arr (Content Dir, a) CS.Item
nixScriptX impure script scripts params = proc (scriptDir, a) -&gt; do
  env &lt;- mergeFiles -&lt; absScripts scriptDir
  external' props (\(s, args) -&gt; ExternalTask
        { _etCommand = &quot;perl&quot;
        , _etParams = contentParam (s ^&lt;/&gt; script) : params args
        , _etWriteToStdOut = NoOutputCapture
        , _etEnv = [(&quot;NIX_PATH&quot;, envParam &quot;NIX_PATH&quot;)] }) -&lt; (env, a)
  where
    props = def { ep_impure = impure }
    absScripts sd = map (sd ^&lt;/&gt;) (script : scripts)</code></pre>
<p>The use of <code>perl</code> as the command relies on <a href="http://perldoc.perl.org/perlrun.html">the behaviour</a> of <code>perl</code> that it will execute the <code>#!</code> line if it does not contain the word “perl”. Yes, this <a href="https://askubuntu.com/questions/850384/is-there-a-command-for-running-a-script-according-to-its-shebang-line/850387">is dirty</a>.</p>
<p>It would be desirable to set <code>NIX_PATH</code> to a fixed <code>nixpkgs</code> checkout by passing a tarball directly but this worked for now.</p>
<p>All the steps are then defined in terms of <code>nixScriptX</code> indirectly as two helper functions are defined for the two cases of a pure or impure scripts.</p>
<pre><code>nixScript = nixScriptX False
impureNixScript = nixScriptX True</code></pre>
<h2 id="step-1---finding-the-map-information">Step 1 - Finding the map information</h2>
<p>Now to the nitty gritty details.</p>
<p>Firstly, I had to decouple the processing of finding the map metainformation from downloading the image. Otherwise, I would end up doing a lot of redundant work downloading images multiple times.</p>
<p>The python script <code>scraper.py</code> executes a selenium driver to extract the map information. For each map, the metainformation is serialised to its own file in the output directory.</p>
<pre><code>scrape = impureNixScript [relfile|scraper.py|] [[relfile|shell.nix|]]
          (\() -&gt; [ outParam ])</code></pre>
<p>This step is marked as impure as we have to run it every time the flow runs to work out if we need to perform any more work.</p>
<p>It is important that the filename of the serialised information is the same if the content of the file is the same. Otherwise, <code>funflow</code> will calculate a different hash for the file. As such, we compute our own hash of the metainformation for the name the serialised file.</p>
<p>In the end the output directory looks like:</p>
<pre><code>9442c7eaa81f82f7e9889f6ee8382e8d047df76db2d5f6a6983d1c82399a2698.pickle
5e7e6994db565126a942d66a9435454d8b55cd7d3023dd37f64eca7bbb46df1f.pickle
...</code></pre>
<h3 id="gotcha-1-using-listdircontents-defeats-caching">Gotcha 1: Using <code>listDirContents</code> defeats caching</h3>
<p>Now that we have a directory containing all the metainformation, we want to split it up and then execute the fetching, converting and warping in parallel for all the images. My first attempt was</p>
<pre><code>meta_dir &lt;- step All &lt;&lt;&lt; scrape -&lt; (script_dir, ())
keys &lt;- listDirContents -&lt; meta_dir</code></pre>
<p>but this did not work and even if the keys remained the same, the images would be refetched. The problem was <a href="https://hackage.haskell.org/package/funflow-1.3.2/docs/Control-Funflow-Steps.html#v:listDirContents"><code>listDirContents</code></a> does not have the correct caching behaviour.</p>
<p><code>listDirContents</code> takes a <code>Content Dir</code> and returns a <code>[Content File]</code> as required but the <code>[Content File]</code> are pointers into places into the <code>Content Dir</code>. This means that if the location of <code>Content Dir</code> changes (if there are any changes or new additions to any files in the directory) then the location of <em>all</em> the <code>[Content File]</code> will also be changed. This means the next stage of recompilation will be triggered despite being unnecessary.</p>
<p>Instead, we have to put each file in the directory into its own store location so that the its location depends only on itself rather than the other contents of the directory. I defined the <code>splitDir</code> combinator in order to do this.</p>
<pre><code>splitDir :: ArrowFlow eff ex arr =&gt; arr (Content Dir) ([Content File])
splitDir = proc dir -&gt; do
  (_, fs) &lt;- listDirContents -&lt; dir
  mapA reifyFile -&lt; fs


-- Put a file, which might be a pointer into a dir, into its own store
-- location.
reifyFile :: ArrowFlow eff ex arr =&gt; arr (Content File) (Content File)
reifyFile = proc f -&gt; do
  file &lt;- getFromStore return -&lt; f
  putInStoreAt (\d fn -&gt; copyFile fn d) -&lt; (file, CS.contentFilename f)</code></pre>
<p>It could be improved by using a hardlink rather than <code>copyFile</code>.</p>
<h2 id="step-2-download-convert-and-warp">Step 2: Download, convert and warp</h2>
<p>Now we have split the metainformation up into individual components we have to download, convert and warp the map files.</p>
<p>We define three flows to do this which correspond to three different scripts.</p>
<pre><code>fetch = nixScript [relfile|fetch.py|] [[relfile|shell.nix|]]
          (\metadata -&gt; [ outParam, contentParam metadata ])

convertToGif = nixScript [relfile|convert_gif|] []
                (\dir -&gt; [ pathParam (IPItem dir), outParam ])

warp = nixScript [relfile|do_warp|] []
        (\dir -&gt; [ pathParam (IPItem dir), outParam ])</code></pre>
<p>Each script takes an individual input file and produces output in a directory specified by <code>funflow</code>.</p>
<p><code>fetch.py</code> is a python script whilst <code>convert_gif</code> and <code>do_warp</code> are bash scripts. We can treat them uniformly because of the <code>nix-shell</code> shebang.</p>
<p>These steps are all cached by default because they are external processes.</p>
<h2 id="step-3-merge-the-images-together">Step 3: Merge the images together</h2>
<p>In order to get a good looking result, we need to group together the processed images into groups of overlapping images. This time we will use a python script again invoked in a similar manner. The output is a directory of files which specify the groups, remember:</p>
<ol type="1">
<li>We have to be careful naming the files so that the names remain stable across compilation. In my original program the names were supplied by a counter but now they are the hash of the files which were used to create the group.</li>
<li>We have to use <code>splitDir</code> after creating the output to put each group file into it’s own store location so the next recompilation step will work.</li>
</ol>
<pre><code>mergeRasters = nixScript [relfile|merge-rasters.py|] [[relfile|merge-rasters.nix|]]
                (\rs -&gt; outParam : map contentParam rs )</code></pre>
<p>This command also relies on <code>merge-rasters.nix</code> which sets up the correct python environment to run the script.</p>
<h3 id="gotcha-2-mergedirs-can-also-defeat-caching">Gotcha 2: <code>mergeDirs</code> can also defeat caching</h3>
<p>The original implementation of this used <code>mergeDirs :: arr [Content File] (Content Dir)</code> in order to group together the files and pass a single directory to <code>merge-rasters.py</code>.</p>
<p>However, this suffers a similar problem to <code>listDirContents</code> as <code>mergeDirs</code> will create a new content store entry which contains all the files in the merge directories. The hash of this store location will then depend on the whole contents of the directory. In this case these file paths ended up in the output so it would cause the next steps to recompile even if nothing had changed.</p>
<p>In this case, we would prefer a “logical” group which groups the files together with a stable filename which wouldn’t affect caching.</p>
<p>The workaround for now was to use <code>splitDir</code> again to put each processed image into its own storage path and then pass each filename individually to <code>merge-rasters.py</code> rather than a directory as before.</p>
<h2 id="step-4-making-the-tiles">Step 4: Making the tiles</h2>
<p>Making the tiles is another straightforward step which takes each of the groups and makes the necessary tiles for that group.</p>
<pre><code>makeTiles = nixScript [relfile|make_tiles|] [] (\dir -&gt; [ contentParam dir, outParam, textParam &quot;16&quot; ])</code></pre>
<h3 id="gotcha-3-mergedirs-doesnt-merge-duplicate-files">Gotcha 3: <code>mergeDirs</code> doesn’t merge duplicate files</h3>
<p>Once we have made all the tiles we need to merge them all together. This is safe as we already ensured that they didn’t overlap each other. The problem is that <code>mergeDirs</code> will not merge duplicate files. The <code>make_tiles</code> step creates some unnecessary files which we don’t need but would cause <code>mergeDirs</code> to fail as they are contained in the output of each directory.</p>
<p>The solution was to write my own version of <code>mergeDirs</code> which checks to see whether a file already exists before trying to merge it. It would be more hygienic to ensure that the directories I was trying to merge were properly distinct but this worked well for this use case.</p>
<h2 id="step-5-creating-the-static-site">Step 5: Creating the static site</h2>
<p>Our final script is a python script which creates the static site displaying all the markers and the map tiles. It takes the output of processing all the images and the metainformation to produce a single html file.</p>
<pre><code>leaflet &lt;- step All &lt;&lt;&lt; makeLeaflet -&lt; ( script_dir, (merge_dir, meta_dir))</code></pre>
<p>The final step then merges together the static page and all the tiles. This is a nice bundle we can directly upload and serve our static site.</p>
<pre><code>mergeDirs -&lt; [leaflet, tiles]</code></pre>
<h2 id="putting-it-all-together">Putting it all together</h2>
<p>The complete flow is shown below:</p>
<pre><code>mainFlow :: SimpleFlow () (Content Dir)
mainFlow = proc () -&gt; do
  cwd &lt;- stepIO (const getCurrentDir) -&lt; ()
  script_dir &lt;- copyDirToStore -&lt; (DirectoryContent (cwd &lt;/&gt; [reldir|scripts/|]), Nothing)

	# Step 1
  meta_dir &lt;- step All &lt;&lt;&lt; scrape -&lt; (script_dir, ())
  keys &lt;- splitDir -&lt; meta_dir
	# Step 2
  maps &lt;- mapA (fetch) -&lt; [( script_dir, event) | event &lt;- keys]
  mapJpgs &lt;- mapA convertToGif -&lt; [(script_dir, m) | m &lt;- maps]
  merge_dir &lt;- mergeDirs' &lt;&lt;&lt; mapA (step All) &lt;&lt;&lt; mapA warp -&lt; [(script_dir, jpg) | jpg &lt;- mapJpgs ]
  toMerge &lt;- splitDir -&lt; merge_dir
	# Step 3
  vrt_dir &lt;- step All &lt;&lt;&lt; mergeRasters -&lt; (script_dir, toMerge)
  merged_vrts &lt;- splitDir -&lt; vrt_dir
	# Step 4
  tiles &lt;- mergeDirs' &lt;&lt;&lt; mapA (step All) &lt;&lt;&lt; mapA makeTiles -&lt; [(script_dir, vrt) | vrt &lt;- merged_vrts]

	# Step 5
  leaflet &lt;- step All &lt;&lt;&lt; makeLeaflet -&lt; ( script_dir, (merge_dir, meta_dir))

  mergeDirs -&lt; [leaflet, tiles]</code></pre>
<p>Once all the kinks are ironed out – it’s quite short but a very powerful specification which avoids a lot of redundant work being carried out.</p>
<h3 id="gotcha-4-copydirtostore-can-defeat-caching">Gotcha 4: <code>copyDirToStore</code> can defeat caching</h3>
<p>Using <code>copyDirToStore</code> seems much more convenient than copying each script into the store manually but it can again have confusing caching behaviour. The hash of the store location for <code>script_dir</code> depends on the whole <code>script_dir</code> directory. If you change any file in the directory then the hash of it will change. This means that all steps will recompile if you modify any script!</p>
<p>This is the reason for the <code>mergeFiles</code> call in <code>nixScriptX</code>. <code>mergeFiles</code> will take the necessary files from <code>script_dir</code> and put them into their own store directory. The hash of this directory will only depend on the files necessary for that step.</p>
<h2 id="running-the-flow">Running the flow</h2>
<p>The flow is run with the simple local runner. We pass in a location for the local store to the runner which is just a local directory in this case. The library has support for more complicated runners but I haven’t explored using those yet.</p>
<pre><code>main :: IO ()
main = do
    cwd &lt;- getCurrentDir
    r &lt;- withSimpleLocalRunner (cwd &lt;/&gt; [reldir|funflow-example/store|]) $ \run -&gt;
      run (mainFlow &gt;&gt;&gt; storePath) ()
    case r of
      Left err -&gt;
        putStrLn $ &quot;FAILED: &quot; ++ displayException err
      Right out -&gt; do
        putStrLn $ &quot;SUCCESS&quot;
        putStrLn $ toFilePath out</code></pre>
<h3 id="displaying-the-outpath">Displaying the outpath</h3>
<p>A nice feature of <code>nix-build</code> is that it displays the path of the final output in the nix store once the build has finished. This is possible to replicate using <code>funflow</code> after defining your own combinator. It would be good to put this in the standard library.</p>
<pre><code>storePath :: ArrowFlow eff ex arr =&gt; arr (Content Dir) (Path Abs Dir)
storePath = getFromStore return</code></pre>
<p>It means that we can run our flow and deploy the site in a single command given we have a script which performs the deployment given an output path.</p>
<p>Mine looks a bit like:</p>
<pre><code>#! /usr/bin/env nix-shell
#! nix-shell -i bash -p awscli
if [[ $# -eq 0 ]] ; then
     echo 'Must pass output directory'
     exit 1
fi
aws s3 sync $1 s3://&lt;bucket-name&gt;</code></pre>
<p>Putting them together:</p>
<pre><code>cabal new-run | ./upload-s3</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>Once everything is set up properly, <code>funflow</code> is a joy to use. It abstracts beautifully away from the annoying problems of scheduling and caching leaving the core logic visible. An unfortunate consequence of the intensional store model is that debugging why a build step is not being cached can be very time consuming and fiddly. When I explain the problems I faced, they are obvious but each one required careful thought and reading the source code to understand the intricacies of each of the different operations.</p>
<p>It was also very pleasant to combine using <code>nix</code> and <code>funflow</code> rather than the suggested <code>docker</code> support.</p>
<h2 id="related-links">Related Links</h2>
<ul>
<li><a href="http://mpickering.github.io/maps.html">Map of orienteering maps</a></li>
<li><a href="https://github.com/mpickering/rg-map">Source code</a></li>
<li><a href="https://www.reddit.com/r/haskell/comments/9f7kq9/using_funflow_to_cache_a_nix_based_workflow/">Reddit comments</a></li>
</ul>

            </div>
          </div>
        </div>
      </div>
    </body>
</html>
